{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MNIST Largest Number Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K\n",
    "\n",
    "# Set random seeds EVERYWHERE:\n",
    "seed = 123\n",
    "rand = np.random.RandomState(seed)\n",
    "os.environ['PYTHONHASHSEED'] = '{}'.format(rand.randint(2**32))\n",
    "np.random.seed(rand.randint(2**32))\n",
    "rn.seed(rand.randint(2**32))\n",
    "tf.set_random_seed(rand.randint(2**32))\n",
    "\n",
    "# Make TensorFlow deterministic:\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Even after all this machinery the weights are only Îµ-close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many MNIST numbers should be available for sampling in the end?\n",
    "test_size = 60000\n",
    "\n",
    "# Final dataset:\n",
    "n_train = 10000\n",
    "n_test = 10000\n",
    "n_objects = 10\n",
    "n_features = 128\n",
    "\n",
    "output_name = 'largest_mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=\"./\")\n",
    "X_raw = mnist['data'].reshape(-1, 28, 28) / 255.\n",
    "y = mnist['target']\n",
    "num_classes = len(np.unique(y))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plot_file =  \"image.svg\"\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X_raw[68016], cmap = 'gray')\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.savefig(plot_file, dpi=None, facecolor='w', edgecolor='w', orientation='portrait', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Split into Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_raw_train, X_raw_test, y_train, y_test = train_test_split(\n",
    "    X_raw, y,\n",
    "    test_size=test_size,\n",
    "    random_state=rand,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train CNN for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "\n",
    "regularizer = l2(1e-4)\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "#model = Sequential()\n",
    "inp = Input(input_shape)\n",
    "tr = Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,\n",
    "                 kernel_regularizer=regularizer,\n",
    "                 use_bias=False)(inp)\n",
    "tr = MaxPooling2D()(tr)\n",
    "tr = BatchNormalization()(tr)\n",
    "tr = Conv2D(64, (5, 5), activation='relu',\n",
    "                 kernel_regularizer=regularizer,\n",
    "                 use_bias=False)(tr)\n",
    "tr = MaxPooling2D()(tr)\n",
    "tr = BatchNormalization()(tr)\n",
    "tr = Flatten()(tr)\n",
    "tr = Dense(1024, activation='relu', kernel_regularizer=regularizer, use_bias=False)(tr)\n",
    "tr = BatchNormalization()(tr)\n",
    "tr = Dense(n_features, activation='relu', kernel_regularizer=regularizer)(tr)\n",
    "tr = BatchNormalization()(tr)\n",
    "out = Dense(num_classes, activation='softmax', kernel_regularizer=regularizer)(tr)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model_feat = Model(inputs=inp, outputs=tr)\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def schedule(ep):\n",
    "    if ep < 10:\n",
    "        return 1e-2\n",
    "    if ep < 20:\n",
    "        return 1e-3\n",
    "    return 1e-4\n",
    "lrschedule = LearningRateScheduler(schedule)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=SGD(lr=1e-3, momentum=0.9, nesterov=True), metrics=['accuracy'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3575 - acc: 0.9301 - val_loss: 0.2420 - val_acc: 0.9630\n",
      "Epoch 2/15\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.1818 - acc: 0.9871 - val_loss: 0.2332 - val_acc: 0.9670\n",
      "Epoch 3/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1513 - acc: 0.9962 - val_loss: 0.2166 - val_acc: 0.9710\n",
      "Epoch 4/15\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.1439 - acc: 0.9978 - val_loss: 0.2181 - val_acc: 0.9740\n",
      "Epoch 5/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1381 - acc: 0.9996 - val_loss: 0.2075 - val_acc: 0.9730\n",
      "Epoch 6/15\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.1354 - acc: 0.9999 - val_loss: 0.2075 - val_acc: 0.9770\n",
      "Epoch 7/15\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.1333 - acc: 1.0000 - val_loss: 0.2079 - val_acc: 0.9780\n",
      "Epoch 8/15\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.1317 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.9770\n",
      "Epoch 9/15\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.1303 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.9760\n",
      "Epoch 10/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1297 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 0.9790\n",
      "Epoch 11/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1290 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9790\n",
      "Epoch 12/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1287 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9790\n",
      "Epoch 13/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1288 - acc: 1.0000 - val_loss: 0.2026 - val_acc: 0.9790\n",
      "Epoch 14/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1285 - acc: 1.0000 - val_loss: 0.2025 - val_acc: 0.9790\n",
      "Epoch 15/15\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1284 - acc: 1.0000 - val_loss: 0.2027 - val_acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ec0aa0c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_raw_train[..., None], keras.utils.to_categorical(y_train, num_classes),\n",
    "          batch_size=64, epochs=15, verbose=1, validation_split=0.1, callbacks=[lrschedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CNN to transform images to high-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_feat = model_feat.predict(X_raw_test[...,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_raw_features.npy\", X_raw_feat)\n",
    "np.save(\"y_labels.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_total = n_train + n_test\n",
    "largest_numbers = rand.randint(1, num_classes, size=n_total)\n",
    "X = np.empty((n_total, n_objects, n_features))\n",
    "y_number = np.empty((n_total, n_objects), dtype=int)\n",
    "for i in range(n_total):\n",
    "    remaining = X_raw_feat[y_test <= largest_numbers[i]]\n",
    "    while True:\n",
    "        indeces = rand.choice(len(remaining), size=n_objects, replace=False)\n",
    "        X[i] = remaining[indeces]\n",
    "        y_number[i] = y_test[y_test <= largest_numbers[i]][indeces]\n",
    "        if largest_numbers[i] in y_number[i]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (y_number == largest_numbers[:, None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=rand, test_size=n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"{}_X_train.npy\".format(output_name), X_train)\n",
    "np.save(\"{}_X_test.npy\".format(output_name), X_test)\n",
    "np.save(\"{}_Y_train.npy\".format(output_name), Y_train)\n",
    "np.save(\"{}_Y_test.npy\".format(output_name), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
