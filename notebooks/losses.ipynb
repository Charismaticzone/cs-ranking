{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prithag/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/prithag/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "proj_path = os.path.abspath(os.path.join('..'))\n",
    "if proj_path not in sys.path:\n",
    "    sys.path.append(proj_path)\n",
    "\n",
    "# Create first network with Keras\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Merge\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from csrank.util import *\n",
    "from csrank.metrics import *\n",
    "from csrank.dataset_reader import SyntheticDatasetGenerator\n",
    "from scipy.stats import kendalltau, spearmanr, rankdata\n",
    "from itertools import combinations\n",
    "from sklearn.utils import check_random_state\n",
    "rs = np.random.RandomState(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_objects = 5\n",
    "n_instances = 5\n",
    "b = np.array([rs.choice(n_objects, replace=False, size=n_objects) for _ in range(n_instances)])\n",
    "c = rs.uniform(size=(n_instances,n_objects))\n",
    "orderings = np.array([rankdata(pred).astype(int)-1 for pred in c])\n",
    "print(b)\n",
    "orderings[0] = b[0]\n",
    "print(orderings)\n",
    "print(np.equal(orderings,b))\n",
    "print(rankdata([0, 5, 3.5, 2.5])-1)\n",
    "np.all(np.equal(orderings,b),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rankings: \n",
      " [[0. 1. 2.]\n",
      " [0. 1. 2.]\n",
      " [2. 1. 0.]\n",
      " [1. 2. 0.]\n",
      " [1. 2. 0.]\n",
      " [2. 0. 1.]\n",
      " [0. 1. 2.]\n",
      " [2. 0. 1.]\n",
      " [0. 2. 1.]\n",
      " [2. 0. 1.]]\n",
      "rankings: \n",
      " [[1.5 1.5 0. ]\n",
      " [1.5 1.5 0. ]\n",
      " [0.  1.  2. ]\n",
      " [1.  0.  2. ]\n",
      " [1.  0.  2. ]\n",
      " [0.  2.  1. ]\n",
      " [2.  1.  0. ]\n",
      " [0.  2.  1. ]\n",
      " [2.  0.  1. ]\n",
      " [0.  2.  1. ]]\n",
      "----------------------------------------------------------\n",
      "kendall scipy: 0.13333333333333341\n",
      "kendall: 0.13333333\n",
      "----------------------------------------------------------\n",
      "spearman scipy: -0.2\n",
      "spearman: 0.25\n",
      "----------------------------------------------------------\n",
      "cal rank loss: 0.4333333333333333\n",
      "zero_one_for_scores:  0.43333334\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    n_objects = 3\n",
    "    n_instances = 10\n",
    "    n = K.placeholder(dtype='int32', name='n')\n",
    "    b = K.placeholder(dtype='float32', shape=(None, n_objects), name='b')\n",
    "    c = K.placeholder(dtype='float32', shape=(None, n_objects), name='c')\n",
    "    result = kendalls_tau_for_scores(b, c)\n",
    "    result2 = spearman_correlation_for_scores(b, c)\n",
    "    result3 = zero_one_rank_loss_for_scores(b,c)\n",
    "    result4 = get_rankings_tensor(n,c)\n",
    "    b_fill = np.array([rs.choice(n_objects, replace=False, size=n_objects) for _ in range(n_instances)])\n",
    "    c_fill = rs.uniform(size=(n_instances, n_objects))\n",
    "    c_fill[0:2,1] = c_fill[0:2,0]\n",
    "    rankings = scores_to_rankings(c_fill)\n",
    "    print('rankings: \\n' , result4.eval(feed_dict={n:n_objects, c: c_fill}))\n",
    "    print('rankings: \\n' , rankings)\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print('kendall scipy:',kendalls_mean_np(b_fill,c_fill))\n",
    "    print('kendall:', result.eval(feed_dict={b: b_fill, c: c_fill}))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print('spearman scipy:',spearman_mean_np(b_fill,c_fill))\n",
    "    print('spearman:',result2.eval(feed_dict={b: b_fill, c: c_fill}))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print('cal rank loss:',zero_one_rank_loss_for_scores_ties_np(b_fill,c_fill))\n",
    "    print('zero_one_for_scores: ',result3.eval(feed_dict={b: b_fill, c: c_fill}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_instances(features):\n",
    "    pairs = np.array(list(combinations(features, 2)))\n",
    "   \n",
    "    n_pairs = len(pairs)\n",
    "    neg_indices = np.arange(0, n_pairs, 2)\n",
    "    \n",
    "    a,b = np.copy(pairs[neg_indices,0]), np.copy(pairs[neg_indices,1])\n",
    "    pairs[neg_indices,1] = a\n",
    "    pairs[neg_indices,0] = b\n",
    "   \n",
    "    X1 = pairs[:,0]\n",
    "    X2 = pairs[:,1]\n",
    "    Y_double = np.ones([n_pairs,1]) * np.array([1,0])\n",
    "    Y_single = np.repeat(1, n_pairs)\n",
    "    \n",
    "    Y_double[neg_indices] = [0,1]\n",
    "    Y_single[neg_indices] = 0\n",
    "    return X1, X2, Y_double, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csrank.dataset_reader.objectranking.util import generate_pairwise_instances\n",
    "def generate_complete_pairwise_dataset(X, orderings):\n",
    "    n_instances, n_objects, n_features = X.shape\n",
    "    orderings = orderings.astype(int)\n",
    "    X_sorted = [X[i, orderings[i], :] for i in range(n_instances)]\n",
    "    Y_double = np.empty((0, 2))\n",
    "    X1 = np.empty((0, n_features))\n",
    "    X2 = np.empty((0, n_features))\n",
    "    Y_single = np.empty((0, 1))\n",
    "    for features in X_sorted:\n",
    "        x1, x2, y1, y2 = generate_pairwise_instances(features)\n",
    "        X1 = np.append(X1, x1, axis=0)\n",
    "        X2 = np.append(X2, x2, axis=0)\n",
    "        Y_double = np.append(Y_double, y1, axis=0)\n",
    "        Y_single = np.append(Y_single, y2)\n",
    "    X_train = X1 - X2\n",
    "    return X_train, X1, X2, Y_double, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "dr = SyntheticDatasetGenerator(n_train_instances=10, n_test_instances=10, n_objects=173,n_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148780, 2)\n",
      "145 ms ± 6.76 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "X, orderings,_,_ = dr.get_single_train_test_split()\n",
    "X_train, X1, X2, Y_double, Y_single = generate_complete_pairwise_dataset(X,orderings)\n",
    "print(X_train.shape)\n",
    "%timeit generate_complete_pairwise_dataset(X,orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_instances(features):\n",
    "    pairs = combinations(features, 2)\n",
    "    Y_double = []\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    Y_single = []\n",
    "    k = 1\n",
    "    for p in pairs:\n",
    "        a = np.array(p[0])\n",
    "        b = np.array(p[1])\n",
    "        if k == 1:\n",
    "            X1.append(a)\n",
    "            X2.append(b)\n",
    "            Y_double.append([1, 0])\n",
    "            Y_single.append(1)\n",
    "        else:\n",
    "            X1.append(b)\n",
    "            X2.append(a)\n",
    "            Y_double.append([0, 1])\n",
    "            Y_single.append(0)\n",
    "        k = k * -1\n",
    "    X1 = np.array(X1)\n",
    "    X2 = np.array(X2)\n",
    "    Y_double = np.array(Y_double)\n",
    "    Y_single = np.array(Y_single)\n",
    "    # X1 = X1[np.newaxis, :, :]\n",
    "    # X2 = X2[np.newaxis, :, :]\n",
    "    return X1, X2, Y_double, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_complete_pairwise_dataset(X, orderings):\n",
    "    n_instances, n_objects, n_features = X.shape\n",
    "    orderings = orderings.astype(int)\n",
    "    X_sorted = [X[i, orderings[i], :] for i in range(n_instances)]\n",
    "    Y_double = np.empty((0, 2))\n",
    "    X1 = np.empty((0, n_features))\n",
    "    X2 = np.empty((0, n_features))\n",
    "    Y_single = np.empty((0, 1))\n",
    "    for features in X_sorted:\n",
    "        x1, x2, y1, y2 = generate_pairwise_instances(features)\n",
    "        X1 = np.append(X1, x1, axis=0)\n",
    "        X2 = np.append(X2, x2, axis=0)\n",
    "        Y_double = np.append(Y_double, y1, axis=0)\n",
    "        Y_single = np.append(Y_single, y2)\n",
    "    X_train = X1 - X2\n",
    "    return X_train, X1, X2, Y_double, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 ms ± 29.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "X, orderings,_,_ = dr.get_single_train_test_split()\n",
    "%timeit generate_complete_pairwise_dataset(X,orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
