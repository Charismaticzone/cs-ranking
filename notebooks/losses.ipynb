{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prithag/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/prithag/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "proj_path = os.path.abspath(os.path.join('..'))\n",
    "if proj_path not in sys.path:\n",
    "    sys.path.append(proj_path)\n",
    "\n",
    "# Create first network with Keras\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Merge\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from bordarank.util import *\n",
    "from bordarank.metrics import *\n",
    "from scipy.stats import kendalltau, spearmanr, rankdata\n",
    "from itertools import combinations\n",
    "from sklearn.utils import check_random_state\n",
    "rs = np.random.RandomState(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_objects = 5\n",
    "n_instances = 5\n",
    "b = np.array([rs.choice(n_objects, replace=False, size=n_objects) for _ in range(n_instances)])\n",
    "c = rs.uniform(size=(n_instances,n_objects))\n",
    "orderings = np.array([rankdata(pred).astype(int)-1 for pred in c])\n",
    "print(b)\n",
    "orderings[0] = b[0]\n",
    "print(orderings)\n",
    "print(np.equal(orderings,b))\n",
    "print(rankdata([0, 5, 3.5, 2.5])-1)\n",
    "np.all(np.equal(orderings,b),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "kendall scipy: -0.08929292929292931\n",
      "kendall: -0.089292884\n",
      "----------------------------------------------------------\n",
      "spearman scipy: -0.13056705670567056\n",
      "spearman: -0.13056707\n",
      "----------------------------------------------------------\n",
      "cal rank loss: 0.5446464646464646\n",
      "zero_one_for_scores:  0.5446465\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    n_objects = 3355\n",
    "    n_instances = 134\n",
    "    n = K.placeholder(dtype='int32', name='n')\n",
    "    b = K.placeholder(dtype='float32', shape=(None, n_objects), name='b')\n",
    "    c = K.placeholder(dtype='float32', shape=(None, n_objects), name='c')\n",
    "    result = kendalls_tau_for_scores(b, c)\n",
    "    result2 = spearman_correlation_for_scores(b, c)\n",
    "    result3 = zero_one_rank_loss_for_scores(b,c)\n",
    "    result4 = get_rankings_tensor(n,c)\n",
    "    b_fill = np.array([rs.choice(n_objects, replace=False, size=n_objects) for _ in range(n_instances)])\n",
    "    c_fill = rs.uniform(size=(n_instances, n_objects))\n",
    "    rankings = scores_to_rankings(c_fill)\n",
    "    #print(b_fill)\n",
    "    #print(c_fill)\n",
    "    #print(\"rankings numpy: \\n\", rankings)\n",
    "    #print(\"rankings: \\n\",result4.eval(feed_dict={n: n_objects, c: c_fill}))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print('kendall scipy:',kendalls_mean_np(b_fill,rankings))\n",
    "    #print('kendall:',result.eval(feed_dict={b: b_fill, c: c_fill}))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print('spearman scipy:',spearman_mean_np(b_fill,rankings))\n",
    "    #print('spearman:',result2.eval(feed_dict={b: b_fill, c: c_fill}))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print('cal rank loss:',zero_one_rank_loss_for_scores_ties_np(b_fill,c_fill))\n",
    "    #print('zero_one_for_scores: ',result3.eval(feed_dict={b: b_fill, c: c_fill}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_instances(features):\n",
    "    pairs = np.array(list(combinations(features, 2)))\n",
    "   \n",
    "    n_pairs = len(pairs)\n",
    "    neg_indices = np.arange(0, n_pairs, 2)\n",
    "    \n",
    "    a,b = np.copy(pairs[neg_indices,0]), np.copy(pairs[neg_indices,1])\n",
    "    pairs[neg_indices,1] = a\n",
    "    pairs[neg_indices,0] = b\n",
    "   \n",
    "    X1 = pairs[:,0]\n",
    "    X2 = pairs[:,1]\n",
    "    Y_double = np.ones([n_pairs,1]) * np.array([1,0])\n",
    "    Y_single = np.repeat(1, n_pairs)\n",
    "    \n",
    "    Y_double[neg_indices] = [0,1]\n",
    "    Y_single[neg_indices] = 0\n",
    "    return X1, X2, Y_double, Y_single\n",
    "\n",
    "def generate_complete_pairwise_dataset(X, orderings):\n",
    "    n_instances, n_objects, n_features = X.shape\n",
    "    orderings = orderings.astype(int)\n",
    "    X_sorted = [X[i, orderings[i], :] for i in range(n_instances)]\n",
    "    Y_double = np.empty((0, 2))\n",
    "    X1 = np.empty((0, n_features))\n",
    "    X2 = np.empty((0, n_features))\n",
    "    Y_single = np.empty((0, 1))\n",
    "    for features in X_sorted:\n",
    "        x1, x2, y1, y2 = generate_pairwise_instances(features)\n",
    "        X1 = np.append(X1, x1, axis=0)\n",
    "        X2 = np.append(X2, x2, axis=0)\n",
    "        Y_double = np.append(Y_double, y1, axis=0)\n",
    "        Y_single = np.append(Y_single, y2)\n",
    "    X_train = X1 - X2\n",
    "    return X_train, X1, X2, Y_double, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_intransitive_medoids' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-79a28a6213ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morderings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_intransitive_medoids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_instances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m173\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_double\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_single\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgenerate_complete_pairwise_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morderings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_intransitive_medoids' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "X, orderings = make_intransitive_medoids(n_instances=3,n_objects=173,n_features=2)\n",
    "X_train, X1, X2, Y_double, Y_single= generate_complete_pairwise_dataset(X,orderings)\n",
    "print(X_train.shape)\n",
    "%timeit generate_complete_pairwise_dataset(X,orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_instances(features):\n",
    "    pairs = combinations(features, 2)\n",
    "    Y_double = []\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    Y_single = []\n",
    "    k = 1\n",
    "    for p in pairs:\n",
    "        a = np.array(p[0])\n",
    "        b = np.array(p[1])\n",
    "        if k == 1:\n",
    "            X1.append(a)\n",
    "            X2.append(b)\n",
    "            Y_double.append([1, 0])\n",
    "            Y_single.append(1)\n",
    "        else:\n",
    "            X1.append(b)\n",
    "            X2.append(a)\n",
    "            Y_double.append([0, 1])\n",
    "            Y_single.append(0)\n",
    "        k = k * -1\n",
    "    X1 = np.array(X1)\n",
    "    X2 = np.array(X2)\n",
    "    Y_double = np.array(Y_double)\n",
    "    Y_single = np.array(Y_single)\n",
    "    # X1 = X1[np.newaxis, :, :]\n",
    "    # X2 = X2[np.newaxis, :, :]\n",
    "    return X1, X2, Y_double, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_complete_pairwise_dataset(X, orderings):\n",
    "    n_instances, n_objects, n_features = X.shape\n",
    "    orderings = orderings.astype(int)\n",
    "    X_sorted = [X[i, orderings[i], :] for i in range(n_instances)]\n",
    "    Y_double = np.empty((0, 2))\n",
    "    X1 = np.empty((0, n_features))\n",
    "    X2 = np.empty((0, n_features))\n",
    "    Y_single = np.empty((0, 1))\n",
    "    for features in X_sorted:\n",
    "        x1, x2, y1, y2 = generate_pairwise_instances(features)\n",
    "        X1 = np.append(X1, x1, axis=0)\n",
    "        X2 = np.append(X2, x2, axis=0)\n",
    "        Y_double = np.append(Y_double, y1, axis=0)\n",
    "        Y_single = np.append(Y_single, y2)\n",
    "    X_train = X1 - X2\n",
    "    return X_train, X1, X2, Y_double, Y_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 137 ms per loop\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "X, orderings = make_intransitive_medoids(n_instances=3,n_objects=173,n_features=2)\n",
    "%timeit generate_complete_pairwise_dataset(X,orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
