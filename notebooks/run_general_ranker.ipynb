{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from bordarank.general_ranking import GeneralObjectRanker\n",
    "from bordarank.objectranking.rank_net import RankNet\n",
    "from bordarank.losses import smooth_rank_loss\n",
    "from keras.optimizers import SGD\n",
    "from bordarank.util import *\n",
    "from bordarank.constants import OBJECT_RANKING\n",
    "from experiments.util import lp_metric_dict\n",
    "from bordarank.dataset_reader import DepthDatasetReader\n",
    "import time\n",
    "from bordarank.callbacks import LRScheduler, DebugOutput, EarlyStoppingWithWeights\n",
    "from keras.callbacks import History\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; \n",
    "sns.set(color_codes=True)\n",
    "plt.style.use(\"seaborn-dark-palette\")\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it with the general ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ERROR_OUTPUT_STRING = 'Out of sample error %s : %0.4f'\n",
    "log_file = os.path.join(os.getcwd(),\"logs\",\"logs.log\")\n",
    "logger = configure_logging_numpy_keras(log_path=log_file, name=\"GeneralRankerTest\")\n",
    "dtype = \"basicSaxena\"\n",
    "logger.info(\"DatasetType {}\".format(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_reader = DepthDatasetReader(dataset_type=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranking_metrics = OrderedDict({'KendallsTau': kendalls_mean_np, 'SpearmanCorrelation': spearman_mean_np,\n",
    "     'ZeroOneRankLoss': zero_one_rank_loss_for_scores_np,\n",
    "     'ZeroOneRankLossTies': zero_one_rank_loss_for_scores_ties_np, \"ZeroOneAccuracy\": zero_one_accuracy_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('KendallsTau', <function kendalls_mean_np at 0x7f32fbe82378>), ('SpearmanCorrelation', <function spearman_mean_np at 0x7f32fbe822f0>), ('ZeroOneRankLoss', <function zero_one_rank_loss_for_scores_np at 0x7f32fbe82510>), ('ZeroOneRankLossTies', <function zero_one_rank_loss_for_scores_ties_np at 0x7f32fbe82488>), ('ZeroOneAccuracy', <function zero_one_accuracy_np at 0x7f32fbe82400>)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_metrics.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = dataset_reader.get_single_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132022, 5, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden_set_units = 512 \n",
    "n_hidden_set_layers = 10\n",
    "n_hidden_joint_units = 512\n",
    "n_hidden_joint_layers = 10\n",
    "lr = LRScheduler()\n",
    "do = DebugOutput(delta=10)\n",
    "hi = History()\n",
    "hi.__name__ = \"History\"\n",
    "n_hidden = 5\n",
    "n_units = 50\n",
    "rf = 3.2548513387780192e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_before = time.time()\n",
    "gor = GeneralObjectRanker(n_object_features=X_train.shape[2],\n",
    "                          n_hidden_set_units=n_hidden_set_units,\n",
    "                          n_hidden_set_layers=n_hidden_set_layers,\n",
    "                          n_hidden_joint_units=n_hidden_joint_units,\n",
    "                          n_hidden_joint_layers=n_hidden_joint_layers,\n",
    "                          batch_size=1024,\n",
    "                          optimizer=SGD(lr=1e-4, momentum=0.9, nesterov=True),\n",
    "                          loss_function=smooth_rank_loss)\n",
    "gor.fit(X_train, Y_train, verbose=False, epochs=50, validation_split=0.1, log_callbacks=[lr,do,hi])\n",
    "time_after=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_before = time.time()\n",
    "rn = RankNet(n_features=X_train.shape[2],\n",
    "                          n_hidden=n_hidden,\n",
    "                          n_units=n_units,\n",
    "                          batch_size=2048,\n",
    "                          optimizer=SGD(lr=1e-4, momentum=0.9, nesterov=True))\n",
    "rn.fit(X_train, Y_train, verbose=False, epochs=10, validation_split=0.1, log_callbacks=[lr,do,hi])\n",
    "time_after=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.60402643330388361,\n",
       " 0.68875136972055595,\n",
       " 0.57266381529084687,\n",
       " 0.62460717826299572,\n",
       " 0.71015352660891196,\n",
       " 0.72908555645097362,\n",
       " 0.74928925986581318,\n",
       " 0.75560723044104539,\n",
       " 0.76233927342537489,\n",
       " 0.76602047807438944]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi.history[\"binary_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rn.scoring_model = rn._create_scoring_model()\n",
    "y_pred_scores = rn.predict_scores(X_test, batch_size=X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_file = os.path.join(os.getcwd(), \"logs\", \"dataset_type_{}_depth_ranknet.h5\".format(dtype))\n",
    "f = h5py.File(pred_file, 'r')\n",
    "y_pred_scores = np.array(f['scores'])\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-84c2626ac14e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmetric_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_for_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mERROR_OUTPUT_STRING\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0meval_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranking_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-84c2626ac14e>\u001b[0m in \u001b[0;36meval_predictions\u001b[0;34m(Y_test, y_pred_scores, ranking_metrics)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mmetric_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_loss_for_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mmetric_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_for_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mERROR_OUTPUT_STRING\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0meval_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranking_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/prithag/pref_learning_neural_network/bordarank/util.py\u001b[0m in \u001b[0;36mget_loss_for_array\u001b[0;34m(metric, y_true, y_pred)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_loss_for_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_tensor_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/prithag/pref_learning_neural_network/bordarank/util.py\u001b[0m in \u001b[0;36mzero_one_rank_loss_for_scores_np\u001b[0;34m(y_true, s_pred)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzero_one_rank_loss_for_scores_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mn_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0mmask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# mask3 = np.equal(s_pred[:, None] - s_pred[:, :, None], 0).astype(float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bordarank.util import get_loss_for_array\n",
    "\n",
    "def eval_predictions(Y_test, y_pred_scores, ranking_metrics):\n",
    "    for name, evaluation_metric in ranking_metrics.items():\n",
    "        if isinstance(Y_test, dict):\n",
    "            metric_loss = get_mean_loss_for_dictionary(logger, evaluation_metric, Y_test, y_pred_scores)\n",
    "        else:\n",
    "            metric_loss = get_loss_for_array(evaluation_metric, Y_test, y_pred_scores)\n",
    "        logger.info(ERROR_OUTPUT_STRING % (name, metric_loss))\n",
    "eval_predictions(Y_test, y_pred_scores, ranking_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "pred_file = os.path.join(os.getcwd(), \"logs\", \"dataset_type_{}_depth_ranknet.h5\".format(dtype))\n",
    "f = h5py.File(pred_file, 'w')\n",
    "f.create_dataset('scores', data=y_pred_scores)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "time_before = time.time()\n",
    "gor = GeneralObjectRanker(n_object_features=X_train[2].shape[2],\n",
    "                          n_hidden_set_units=512,\n",
    "                          n_hidden_set_layers=10,\n",
    "                          n_hidden_joint_units=512,\n",
    "                          n_hidden_joint_layers=10,\n",
    "                          batch_size=512,\n",
    "                          optimizer=SGD(lr=5e-3, momentum=0.9, nesterov=True))\n",
    "gor.fit(X_train[5], Y_train[5], verbose=True, epochs=1000)\n",
    "time_after=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "y_pred_scores = gor.predict_scores(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "eval_predictions(y_pred_scores, ranking_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(time_after - time_before)/60 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "i = 0\n",
    "m = [\"o\", \"^\", \"x\"]\n",
    "c = [\"b\", \"k\", \"r\"]\n",
    "fig =  plt.figure()\n",
    "for name, evaluation_metric in ranking_metrics.items():\n",
    "    logger.info(\"Name {}\".format(name))\n",
    "    losses, total_instances = get_losses_for_dictionary(logger, evaluation_metric, Y_test, y_pred_scores)\n",
    "    losses = dict(zip(keys, values))\n",
    "    x = np.array(list(losses.keys()))\n",
    "    y = np.array(list(losses.values()))\n",
    "    plt.plot(x,y,label=name,color=c[i],marker=m[i])\n",
    "    i = i+1\n",
    "plt.title(\"GeneralRankerPerformance\")\n",
    "plt.legend(loc=\"best\");\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
