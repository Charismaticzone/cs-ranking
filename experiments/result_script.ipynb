{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from csrank.util import setup_logger\n",
    "from experiments.dbconnection import DBConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results.log')\n",
    "setup_logger(log_path=log_path)\n",
    "logger = logging.getLogger('Result parsing')\n",
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "RESULTS = 'results'\n",
    "DATASET = \"mnist_dc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema='pymc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs available [1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019]\n",
      "Job selected : 1002\n",
      "\n",
      "job_id => 1002\n",
      "fold_id => 0\n",
      "dataset => synthetic_dc\n",
      "learner => nested_logit_model\n",
      "experiment_schema => results\n",
      "experiment_table => discrete_choice\n",
      "dataset_params => {'dataset_type': 'medoid', 'n_test_instances': 100000, 'n_train_instances': 10000, 'n_features': 5, 'n_objects': 10}\n",
      "fit_params => {'sampler': 'vi', 'sample_params': {'tune': 10, 'draws': 10, 'chains': 1, 'njobs': 1}, 'vi_params': {'n': 30000, 'method': 'advi'}, 'draws': 500}\n",
      "learner_params => {}\n",
      "hp_ranges => {'nested_logit_model': {'loss_function': ['categorical_crossentropy', 'binary_crossentropy', 'categorical_hinge'], 'regularization': ['l1', 'l2'], 'n_nests': [2, 5]}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 20\n",
      "is_gpu => False\n",
      "seed => 42\n",
      "inner_folds => 1\n",
      "duration => 3D\n",
      "learning_problem => discrete_choice\n",
      "validation_loss => None\n",
      "hash_value => a63d1a20a2b93dd5d7955f921aaf2656fe5ab70a\n",
      "job_allocated_time => 2018-07-26 13:53:01.920526\n",
      "\n",
      "Hash_string fold_id:0learner:nested_logit_modeldataset_params:{'dataset_type': 'medoid', 'n_test_instances': 100000, 'n_train_instances': 10000, 'n_features': 5, 'n_objects': 10}fit_params:{'sampler': 'vi', 'sample_params': {'tune': 10, 'draws': 10, 'chains': 1, 'njobs': 1}, 'vi_params': {'n': 30000, 'method': 'advi'}, 'draws': 500}learner_params:{}hp_ranges:{'nested_logit_model': {'loss_function': ['categorical_crossentropy', 'binary_crossentropy', 'categorical_hinge'], 'regularization': ['l1', 'l2'], 'n_nests': [2, 5]}}hp_fit_params:{}inner_folds:1validation_loss:None\n",
      "The job 1002 is inserted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.fetch_job_arguments(cluster_id=1234)\n",
    "self.job_description['job_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'synthetic_dc',\n",
       " 'dataset_params': {'dataset_type': 'medoid',\n",
       "  'n_features': 5,\n",
       "  'n_objects': 10,\n",
       "  'n_test_instances': 100000,\n",
       "  'n_train_instances': 10000},\n",
       " 'duration': '3D',\n",
       " 'experiment_schema': 'results',\n",
       " 'experiment_table': 'discrete_choice',\n",
       " 'fit_params': {'draws': 500,\n",
       "  'sample_params': {'chains': 1, 'draws': 10, 'njobs': 1, 'tune': 10},\n",
       "  'sampler': 'vi',\n",
       "  'vi_params': {'method': 'advi', 'n': 30000}},\n",
       " 'fold_id': 0,\n",
       " 'hash_value': 'f359fe9df00f6bd1cbf62626c9cf37f98fe7a993',\n",
       " 'hp_fit_params': {},\n",
       " 'hp_iters': 20,\n",
       " 'hp_ranges': {'generalized_extreme_value': {'loss_function': ['categorical_crossentropy',\n",
       "    'binary_crossentropy',\n",
       "    'categorical_hinge'],\n",
       "   'n_nests': [3, 6],\n",
       "   'regularization': ['l1', 'l2']}},\n",
       " 'inner_folds': 1,\n",
       " 'is_gpu': False,\n",
       " 'job_allocated_time': datetime.datetime(2018, 7, 26, 13, 36, 7, 598287),\n",
       " 'job_id': 1003,\n",
       " 'learner': 'generalized_extreme_value',\n",
       " 'learner_params': {},\n",
       " 'learning_problem': 'discrete_choice',\n",
       " 'seed': 42,\n",
       " 'validation_loss': 'None'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Inserting results: INSERT INTO pymc3.avail_jobs (dataset, dataset_params, duration, experiment_schema, experiment_table, fit_params, fold_id, hash_value, hp_fit_params, hp_iters, hp_ranges, inner_folds, is_gpu, job_allocated_time, job_id, learner, learner_params, learning_problem, seed, validation_loss) SELECT 1, dataset_params, duration, experiment_schema, experiment_table, fit_params, fold_id, hash_value, hp_fit_params, hp_iters, hp_ranges, inner_folds, is_gpu, job_allocated_time, job_id, learner, learner_params, learning_problem, seed, validation_loss FROM pymc3.avail_jobs where pymc3.avail_jobs.job_id = 1001 RETURNING job_id\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "FEHLER:  doppelter Schlüsselwert verletzt Unique-Constraint »avail_jobs_job_id_pk«\nDETAIL:  Schlüssel »(job_id)=(1001)« existiert bereits.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-71b17cb7cc8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inserting results: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
      "\u001b[0;31mIntegrityError\u001b[0m: FEHLER:  doppelter Schlüsselwert verletzt Unique-Constraint »avail_jobs_job_id_pk«\nDETAIL:  Schlüssel »(job_id)=(1001)« existiert bereits.\n"
     ]
    }
   ],
   "source": [
    "job_desc = self.job_description\n",
    "job_desc['fold_id'] = 1\n",
    "job_id = job_desc['job_id']\n",
    "#del job_desc['job_id']\n",
    "keys = list(job_desc.keys())\n",
    "columns = ', '.join(keys)\n",
    "import numpy as np\n",
    "print(index)\n",
    "keys[0] = str(self.job_description['fold_id'])\n",
    "#keys[-2] = self.job_description[\"hash_value\"]\n",
    "values_str = ', '.join(keys)\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "insert_result = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "print(\"Inserting results: {}\".format(insert_result))\n",
    "self.init_connection(cursor_factory=None)\n",
    "self.cursor_db.execute(insert_result)\n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "self.cursor_db.execute(insert_job)\n",
    "print(job_id)\n",
    "print(self.cursor_db.rowcount == 1)\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categoricalaccuracy',\n",
       " 'categoricaltopk2',\n",
       " 'categoricaltopk3',\n",
       " 'categoricaltopk4',\n",
       " 'categoricaltopk5',\n",
       " 'categoricaltopk6']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_choice_metrics = {'CategoricalAccuracy': 1,\n",
    "                           'CategoricalTopK2': 2,\n",
    "                           'CategoricalTopK3': 3,\n",
    "                           'CategoricalTopK4': 4,\n",
    "                           'CategoricalTopK5': 5,\n",
    "                           'CategoricalTopK6': 6}\n",
    "[x.lower() for x in discrete_choice_metrics.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.init_connection()\n",
    "results_table = \"results.discrete_choice\"\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "select_st = \"SELECT dataset_params, learner, categoricalaccuracy, categoricaltopk2, categoricaltopk3, categoricaltopk5, categoricaltopk6  from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset=\\'{2}\\'\".format(\n",
    "    results_table, avail_jobs, DATASET)\n",
    "self.cursor_db.execute(select_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for job in self.cursor_db.fetchall():\n",
    "    values = list(job.values())\n",
    "    keys = list(job.keys())\n",
    "    columns = ['dataset'] +keys[1:]\n",
    "    vals = [job['dataset_params']['dataset_type'].upper()] + values[1:]\n",
    "    data.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "select_st = \"SELECT dataset_params, learner, categoricalaccuracy, categoricaltopk2, categoricaltopk3, categoricaltopk5, categoricaltopk6  from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset='synthetic_dc'\".format(\n",
    "    results_table, avail_jobs)\n",
    "self.cursor_db.execute(select_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>categoricalaccuracy</th>\n",
       "      <th>categoricaltopk2</th>\n",
       "      <th>categoricaltopk3</th>\n",
       "      <th>categoricaltopk5</th>\n",
       "      <th>categoricaltopk6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>ranknet_dc</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>0.6417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDIAN</td>\n",
       "      <td>ranknet_dc</td>\n",
       "      <td>0.5043</td>\n",
       "      <td>0.6437</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>ranknet_dc</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.9872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>fate_dc</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.5799</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.8753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>feta_dc</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset     learner  categoricalaccuracy  categoricaltopk2  \\\n",
       "0   UNIQUE  ranknet_dc               0.1077            0.2162   \n",
       "1   MEDIAN  ranknet_dc               0.5043            0.6437   \n",
       "2  LARGEST  ranknet_dc               0.8901            0.9400   \n",
       "3  LARGEST     fate_dc               0.4177            0.5799   \n",
       "4  LARGEST     feta_dc               0.8600            0.9244   \n",
       "\n",
       "   categoricaltopk3  categoricaltopk5  categoricaltopk6  \n",
       "0            0.3267            0.5378            0.6417  \n",
       "1            0.7272            0.8361            0.8757  \n",
       "2            0.9604            0.9813            0.9872  \n",
       "3            0.6848            0.8254            0.8753  \n",
       "4            0.9510            0.9772            0.9842  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.DataFrame(data, columns=columns)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_full.groupby(['dataset', 'learner'])\n",
    "data = []\n",
    "for name, group in grouped:\n",
    "    one_row = [name[0], str(name[1]).upper()]\n",
    "    std = group.std(axis=0).values\n",
    "    mean = group.mean(axis=0).values\n",
    "    one_row.extend([\"{:.3f}+-{:.3f}\".format(m, s) for m, s in zip(mean, std)])\n",
    "    data.append(one_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>categoricalaccuracy</th>\n",
       "      <th>categoricaltopk2</th>\n",
       "      <th>categoricaltopk3</th>\n",
       "      <th>categoricaltopk5</th>\n",
       "      <th>categoricaltopk6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.418+-nan</td>\n",
       "      <td>0.580+-nan</td>\n",
       "      <td>0.685+-nan</td>\n",
       "      <td>0.825+-nan</td>\n",
       "      <td>0.875+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>FETA_DC</td>\n",
       "      <td>0.860+-nan</td>\n",
       "      <td>0.924+-nan</td>\n",
       "      <td>0.951+-nan</td>\n",
       "      <td>0.977+-nan</td>\n",
       "      <td>0.984+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.890+-nan</td>\n",
       "      <td>0.940+-nan</td>\n",
       "      <td>0.960+-nan</td>\n",
       "      <td>0.981+-nan</td>\n",
       "      <td>0.987+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.902+-0.005</td>\n",
       "      <td>0.964+-0.003</td>\n",
       "      <td>0.984+-0.001</td>\n",
       "      <td>0.996+-0.001</td>\n",
       "      <td>nan+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEDIAN</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.504+-nan</td>\n",
       "      <td>0.644+-nan</td>\n",
       "      <td>0.727+-nan</td>\n",
       "      <td>0.836+-nan</td>\n",
       "      <td>0.876+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDIAN</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.324+-0.045</td>\n",
       "      <td>0.563+-0.080</td>\n",
       "      <td>0.747+-0.098</td>\n",
       "      <td>0.936+-0.069</td>\n",
       "      <td>nan+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.941+-nan</td>\n",
       "      <td>0.972+-nan</td>\n",
       "      <td>0.983+-nan</td>\n",
       "      <td>0.992+-nan</td>\n",
       "      <td>0.995+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>FETA_DC</td>\n",
       "      <td>0.229+-nan</td>\n",
       "      <td>0.336+-nan</td>\n",
       "      <td>0.436+-nan</td>\n",
       "      <td>0.624+-nan</td>\n",
       "      <td>0.710+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.108+-nan</td>\n",
       "      <td>0.216+-nan</td>\n",
       "      <td>0.327+-nan</td>\n",
       "      <td>0.538+-nan</td>\n",
       "      <td>0.642+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.146+-0.003</td>\n",
       "      <td>0.246+-0.005</td>\n",
       "      <td>0.349+-0.005</td>\n",
       "      <td>0.547+-0.003</td>\n",
       "      <td>0.878+-0.155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset     learner categoricalaccuracy categoricaltopk2 categoricaltopk3  \\\n",
       "0  LARGEST     FATE_DC          0.418+-nan       0.580+-nan       0.685+-nan   \n",
       "1  LARGEST     FETA_DC          0.860+-nan       0.924+-nan       0.951+-nan   \n",
       "2  LARGEST  RANKNET_DC          0.890+-nan       0.940+-nan       0.960+-nan   \n",
       "3  LARGEST  RANKSVM_DC        0.902+-0.005     0.964+-0.003     0.984+-0.001   \n",
       "4   MEDIAN  RANKNET_DC          0.504+-nan       0.644+-nan       0.727+-nan   \n",
       "5   MEDIAN  RANKSVM_DC        0.324+-0.045     0.563+-0.080     0.747+-0.098   \n",
       "6   UNIQUE     FATE_DC          0.941+-nan       0.972+-nan       0.983+-nan   \n",
       "7   UNIQUE     FETA_DC          0.229+-nan       0.336+-nan       0.436+-nan   \n",
       "8   UNIQUE  RANKNET_DC          0.108+-nan       0.216+-nan       0.327+-nan   \n",
       "9   UNIQUE  RANKSVM_DC        0.146+-0.003     0.246+-0.005     0.349+-0.005   \n",
       "\n",
       "  categoricaltopk5 categoricaltopk6  \n",
       "0       0.825+-nan       0.875+-nan  \n",
       "1       0.977+-nan       0.984+-nan  \n",
       "2       0.981+-nan       0.987+-nan  \n",
       "3     0.996+-0.001         nan+-nan  \n",
       "4       0.836+-nan       0.876+-nan  \n",
       "5     0.936+-0.069         nan+-nan  \n",
       "6       0.992+-nan       0.995+-nan  \n",
       "7       0.624+-nan       0.710+-nan  \n",
       "8       0.538+-nan       0.642+-nan  \n",
       "9     0.547+-0.003     0.878+-0.155  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.sort_values(by='dataset')\n",
    "df_path = os.path.join(DIR_PATH, 'results' , DATASET+'.csv')\n",
    "df.to_csv(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
       "       65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
       "       82, 83, 84, 85, 86])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.arange(40).reshape(4,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_object_features': 2, 'n_objects': 5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
