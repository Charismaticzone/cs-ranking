{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from csrank.util import setup_logger\n",
    "from experiments.dbconnection import DBConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results.log')\n",
    "setup_logger(log_path=log_path)\n",
    "logger = logging.getLogger('Result parsing')\n",
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "RESULTS = 'results'\n",
    "DATASET = \"mnist_dc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema='pymc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs available [1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019]\n",
      "Job selected : 1012\n",
      "The job 1012 is inserted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.fetch_job_arguments(cluster_id=1234)\n",
    "jself.job_description['job_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting results: INSERT INTO pymc3.avail_jobs (fold_id, dataset, learner, experiment_schema, experiment_table, dataset_params, fit_params, learner_params, hp_ranges, hp_fit_params, hp_iters, is_gpu, seed, inner_folds, duration, learning_problem, validation_loss, hash_value, job_allocated_time) SELECT 1, dataset, learner, experiment_schema, experiment_table, dataset_params, fit_params, learner_params, hp_ranges, hp_fit_params, hp_iters, is_gpu, seed, inner_folds, duration, learning_problem, validation_loss, hash_value, job_allocated_time FROM pymc3.avail_jobs where pymc3.avail_jobs.job_id = 1012 RETURNING job_id\n",
      "1028\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "self.job_description['fold_id'] = 1\n",
    "self.job_description[\"hash_value\"] = self.create_hash_value()\n",
    "job_desc = dict(self.job_description)\n",
    "del job_desc['job_id']\n",
    "job_id = self.job_description['job_id']\n",
    "keys = list(job_desc.keys())\n",
    "columns = ', '.join(keys)\n",
    "keys[0] = str(self.job_description['fold_id'])\n",
    "#keys[-2] = self.job_description[\"hash_value\"]\n",
    "values_str = ', '.join(keys)\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "insert_result = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "print(\"Inserting results: {}\".format(insert_result))\n",
    "self.init_connection(cursor_factory=None)\n",
    "self.cursor_db.execute(insert_result)\n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "self.cursor_db.execute(insert_job)\n",
    "print(id_of_new_row)\n",
    "print(self.cursor_db.rowcount == 1)\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categoricalaccuracy',\n",
       " 'categoricaltopk2',\n",
       " 'categoricaltopk3',\n",
       " 'categoricaltopk4',\n",
       " 'categoricaltopk5',\n",
       " 'categoricaltopk6']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_choice_metrics = {'CategoricalAccuracy': 1,\n",
    "                           'CategoricalTopK2': 2,\n",
    "                           'CategoricalTopK3': 3,\n",
    "                           'CategoricalTopK4': 4,\n",
    "                           'CategoricalTopK5': 5,\n",
    "                           'CategoricalTopK6': 6}\n",
    "[x.lower() for x in discrete_choice_metrics.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.init_connection()\n",
    "results_table = \"results.discrete_choice\"\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "select_st = \"SELECT dataset_params, learner, categoricalaccuracy, categoricaltopk2, categoricaltopk3, categoricaltopk5, categoricaltopk6  from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset=\\'{2}\\'\".format(\n",
    "    results_table, avail_jobs, DATASET)\n",
    "self.cursor_db.execute(select_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for job in self.cursor_db.fetchall():\n",
    "    values = list(job.values())\n",
    "    keys = list(job.keys())\n",
    "    columns = ['dataset'] +keys[1:]\n",
    "    vals = [job['dataset_params']['dataset_type'].upper()] + values[1:]\n",
    "    data.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "select_st = \"SELECT dataset_params, learner, categoricalaccuracy, categoricaltopk2, categoricaltopk3, categoricaltopk5, categoricaltopk6  from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset='synthetic_dc'\".format(\n",
    "    results_table, avail_jobs)\n",
    "self.cursor_db.execute(select_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>categoricalaccuracy</th>\n",
       "      <th>categoricaltopk2</th>\n",
       "      <th>categoricaltopk3</th>\n",
       "      <th>categoricaltopk5</th>\n",
       "      <th>categoricaltopk6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>ranknet_dc</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>0.6417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDIAN</td>\n",
       "      <td>ranknet_dc</td>\n",
       "      <td>0.5043</td>\n",
       "      <td>0.6437</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>ranknet_dc</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.9872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>fate_dc</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.5799</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.8753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>feta_dc</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset     learner  categoricalaccuracy  categoricaltopk2  \\\n",
       "0   UNIQUE  ranknet_dc               0.1077            0.2162   \n",
       "1   MEDIAN  ranknet_dc               0.5043            0.6437   \n",
       "2  LARGEST  ranknet_dc               0.8901            0.9400   \n",
       "3  LARGEST     fate_dc               0.4177            0.5799   \n",
       "4  LARGEST     feta_dc               0.8600            0.9244   \n",
       "\n",
       "   categoricaltopk3  categoricaltopk5  categoricaltopk6  \n",
       "0            0.3267            0.5378            0.6417  \n",
       "1            0.7272            0.8361            0.8757  \n",
       "2            0.9604            0.9813            0.9872  \n",
       "3            0.6848            0.8254            0.8753  \n",
       "4            0.9510            0.9772            0.9842  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.DataFrame(data, columns=columns)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_full.groupby(['dataset', 'learner'])\n",
    "data = []\n",
    "for name, group in grouped:\n",
    "    one_row = [name[0], str(name[1]).upper()]\n",
    "    std = group.std(axis=0).values\n",
    "    mean = group.mean(axis=0).values\n",
    "    one_row.extend([\"{:.3f}+-{:.3f}\".format(m, s) for m, s in zip(mean, std)])\n",
    "    data.append(one_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>categoricalaccuracy</th>\n",
       "      <th>categoricaltopk2</th>\n",
       "      <th>categoricaltopk3</th>\n",
       "      <th>categoricaltopk5</th>\n",
       "      <th>categoricaltopk6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.418+-nan</td>\n",
       "      <td>0.580+-nan</td>\n",
       "      <td>0.685+-nan</td>\n",
       "      <td>0.825+-nan</td>\n",
       "      <td>0.875+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>FETA_DC</td>\n",
       "      <td>0.860+-nan</td>\n",
       "      <td>0.924+-nan</td>\n",
       "      <td>0.951+-nan</td>\n",
       "      <td>0.977+-nan</td>\n",
       "      <td>0.984+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.890+-nan</td>\n",
       "      <td>0.940+-nan</td>\n",
       "      <td>0.960+-nan</td>\n",
       "      <td>0.981+-nan</td>\n",
       "      <td>0.987+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARGEST</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.902+-0.005</td>\n",
       "      <td>0.964+-0.003</td>\n",
       "      <td>0.984+-0.001</td>\n",
       "      <td>0.996+-0.001</td>\n",
       "      <td>nan+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEDIAN</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.504+-nan</td>\n",
       "      <td>0.644+-nan</td>\n",
       "      <td>0.727+-nan</td>\n",
       "      <td>0.836+-nan</td>\n",
       "      <td>0.876+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MEDIAN</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.324+-0.045</td>\n",
       "      <td>0.563+-0.080</td>\n",
       "      <td>0.747+-0.098</td>\n",
       "      <td>0.936+-0.069</td>\n",
       "      <td>nan+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.941+-nan</td>\n",
       "      <td>0.972+-nan</td>\n",
       "      <td>0.983+-nan</td>\n",
       "      <td>0.992+-nan</td>\n",
       "      <td>0.995+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>FETA_DC</td>\n",
       "      <td>0.229+-nan</td>\n",
       "      <td>0.336+-nan</td>\n",
       "      <td>0.436+-nan</td>\n",
       "      <td>0.624+-nan</td>\n",
       "      <td>0.710+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.108+-nan</td>\n",
       "      <td>0.216+-nan</td>\n",
       "      <td>0.327+-nan</td>\n",
       "      <td>0.538+-nan</td>\n",
       "      <td>0.642+-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UNIQUE</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.146+-0.003</td>\n",
       "      <td>0.246+-0.005</td>\n",
       "      <td>0.349+-0.005</td>\n",
       "      <td>0.547+-0.003</td>\n",
       "      <td>0.878+-0.155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset     learner categoricalaccuracy categoricaltopk2 categoricaltopk3  \\\n",
       "0  LARGEST     FATE_DC          0.418+-nan       0.580+-nan       0.685+-nan   \n",
       "1  LARGEST     FETA_DC          0.860+-nan       0.924+-nan       0.951+-nan   \n",
       "2  LARGEST  RANKNET_DC          0.890+-nan       0.940+-nan       0.960+-nan   \n",
       "3  LARGEST  RANKSVM_DC        0.902+-0.005     0.964+-0.003     0.984+-0.001   \n",
       "4   MEDIAN  RANKNET_DC          0.504+-nan       0.644+-nan       0.727+-nan   \n",
       "5   MEDIAN  RANKSVM_DC        0.324+-0.045     0.563+-0.080     0.747+-0.098   \n",
       "6   UNIQUE     FATE_DC          0.941+-nan       0.972+-nan       0.983+-nan   \n",
       "7   UNIQUE     FETA_DC          0.229+-nan       0.336+-nan       0.436+-nan   \n",
       "8   UNIQUE  RANKNET_DC          0.108+-nan       0.216+-nan       0.327+-nan   \n",
       "9   UNIQUE  RANKSVM_DC        0.146+-0.003     0.246+-0.005     0.349+-0.005   \n",
       "\n",
       "  categoricaltopk5 categoricaltopk6  \n",
       "0       0.825+-nan       0.875+-nan  \n",
       "1       0.977+-nan       0.984+-nan  \n",
       "2       0.981+-nan       0.987+-nan  \n",
       "3     0.996+-0.001         nan+-nan  \n",
       "4       0.836+-nan       0.876+-nan  \n",
       "5     0.936+-0.069         nan+-nan  \n",
       "6       0.992+-nan       0.995+-nan  \n",
       "7       0.624+-nan       0.710+-nan  \n",
       "8       0.538+-nan       0.642+-nan  \n",
       "9     0.547+-0.003     0.878+-0.155  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.sort_values(by='dataset')\n",
    "df_path = os.path.join(DIR_PATH, 'results' , DATASET+'.csv')\n",
    "df.to_csv(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
       "       65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
       "       82, 83, 84, 85, 86])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.arange(40).reshape(4,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_object_features': 2, 'n_objects': 5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
