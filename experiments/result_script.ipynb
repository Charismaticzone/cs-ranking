{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from csrank.util import setup_logging\n",
    "from experiments.util import lp_metric_dict\n",
    "import numpy as np\n",
    "from experiments.dbconnection import DBConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results.log')\n",
    "setup_logging(log_path=log_path)\n",
    "logger = logging.getLogger('ResultParsing')\n",
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "datasets = ['synthetic_dc', 'mnist_dc', 'tag_genome_dc', \"letor_dc\", \"sushi_dc\"]\n",
    "DATASET = datasets[4]\n",
    "learning_problem = \"discrete_choice\"\n",
    "results_table = 'results.{}'.format(learning_problem)\n",
    "schema = 'masterthesis'\n",
    "start=3\n",
    "select_jobs = \"SELECT learner_params, dataset_params, hp_ranges, {0}.job_id, dataset, learner, {3} from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset=\\'{2}\\'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_result = \"UPDATE results.discrete_choice set cluster_id = %s, CategoricalAccuracy = %s, CategoricalTopK2 = %s, CategoricalTopK3 = %s, CategoricalTopK4 = %s, CategoricalTopK5 = %s, CategoricalTopK6 = %s  where job_id= %s\"\n",
    "values = (6636228, 0.4343, 0.6603, 0.8295, 0.9504, 1.0000, 1.0000,479)\n",
    "self.init_connection()\n",
    "self.cursor_db.execute(update_result, tuple(values))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letor_string(dp):\n",
    "    y =  str(dp['year']) \n",
    "    n = str(dp['n_objects'])\n",
    "    return \"y_{}_n_{}\".format(y,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CategoricalAccuracy, CategoricalTopK2, CategoricalTopK3, CategoricalTopK4, CategoricalTopK5, CategoricalTopK6'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(lp_metric_dict[learning_problem].keys())\n",
    "keys[-1] = keys[-1].format(6)\n",
    "metrics = ', '.join([x for x in keys])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT learner_params, dataset_params, hp_ranges, results.discrete_choice.job_id, dataset, learner, CategoricalAccuracy, CategoricalTopK2, CategoricalTopK3, CategoricalTopK4, CategoricalTopK5, CategoricalTopK6 from results.discrete_choice INNER JOIN masterthesis.avail_jobs ON results.discrete_choice.job_id = masterthesis.avail_jobs.job_id where masterthesis.avail_jobs.dataset='sushi_dc'\n"
     ]
    }
   ],
   "source": [
    "self.init_connection()\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "select_st = select_jobs.format(results_table, avail_jobs, DATASET, metrics)\n",
    "print(select_st)\n",
    "self.cursor_db.execute(select_st)\n",
    "data = []\n",
    "for job in self.cursor_db.fetchall():\n",
    "    job = dict(job)\n",
    "    n_hidden = job['hp_ranges'][job['learner']].get(\"n_hidden\", [])\n",
    "    if job['hp_ranges'][job['learner']].get(\"n_hidden_set_layers\", None)==[1,8]:\n",
    "        job['learner'] = job['learner']+'_shallow'\n",
    "    elif n_hidden==[1,4] or n_hidden==[1,5]:\n",
    "        job['learner'] = job['learner']+'_shallow'\n",
    "        \n",
    "    if job['learner_params'].get(\"add_zeroth_order_model\", False):\n",
    "        job['learner'] = job['learner']+'_zero'\n",
    "    if \"letor\" in job['dataset']:\n",
    "        job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "    elif \"sushi\" in job['dataset']:\n",
    "        job['dataset'] =  job['dataset']\n",
    "    else:\n",
    "        job['dataset'] = job['dataset_params']['dataset_type']\n",
    "    job['learner'] = job['learner'].upper()\n",
    "    job['dataset'] = job['dataset'].upper()\n",
    "    values = list(job.values())\n",
    "    keys = list(job.keys())\n",
    "    columns = keys[start:]\n",
    "    vals = values[start:]\n",
    "    data.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT learner_params, dataset_params, hp_ranges, results.discrete_choice.job_id, dataset, learner, CategoricalAccuracy, CategoricalTopK2, CategoricalTopK3, CategoricalTopK4, CategoricalTopK5, CategoricalTopK6 from results.discrete_choice INNER JOIN pymc3.avail_jobs ON results.discrete_choice.job_id = pymc3.avail_jobs.job_id where pymc3.avail_jobs.dataset='sushi_dc'\n"
     ]
    }
   ],
   "source": [
    "self.init_connection()\n",
    "avail_jobs = \"{}.avail_jobs\".format(\"pymc3\")\n",
    "select_st = select_jobs.format(results_table, avail_jobs, DATASET, metrics)\n",
    "print(select_st)\n",
    "self.cursor_db.execute(select_st)\n",
    "for job in self.cursor_db.fetchall():\n",
    "    job = dict(job)\n",
    "    if \"letor\" in job['dataset']:\n",
    "        job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "    elif \"sushi\" in job['dataset']:\n",
    "        job['dataset'] =  job['dataset']\n",
    "    else:\n",
    "        job['dataset'] = job['dataset_params']['dataset_type']\n",
    "    job['learner'] = job['learner'].upper()\n",
    "    job['dataset'] = job['dataset'].upper()\n",
    "    values = list(job.values())\n",
    "    keys = list(job.keys())\n",
    "    columns = keys[start:]\n",
    "    vals = values[start:]\n",
    "    data.append(vals)\n",
    "df_full = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>categoricalaccuracy</th>\n",
       "      <th>categoricaltopk2</th>\n",
       "      <th>categoricaltopk3</th>\n",
       "      <th>categoricaltopk4</th>\n",
       "      <th>categoricaltopk5</th>\n",
       "      <th>categoricaltopk6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>540</td>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FETA_DC_SHALLOW_ZERO</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.6030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>413</td>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FETA_DC_SHALLOW_ZERO</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.7190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>538</td>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FETA_DC_SHALLOW_ZERO</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.7920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>541</td>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FETA_DC_SHALLOW_ZERO</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>0.8060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>539</td>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FETA_DC_SHALLOW_ZERO</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.7715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    job_id   dataset               learner  categoricalaccuracy  \\\n",
       "24     540  SUSHI_DC  FETA_DC_SHALLOW_ZERO               0.1190   \n",
       "23     413  SUSHI_DC  FETA_DC_SHALLOW_ZERO               0.2680   \n",
       "6      538  SUSHI_DC  FETA_DC_SHALLOW_ZERO               0.1285   \n",
       "7      541  SUSHI_DC  FETA_DC_SHALLOW_ZERO               0.1935   \n",
       "12     539  SUSHI_DC  FETA_DC_SHALLOW_ZERO               0.0790   \n",
       "\n",
       "    categoricaltopk2  categoricaltopk3  categoricaltopk4  categoricaltopk5  \\\n",
       "24            0.2150            0.3125             0.417            0.5135   \n",
       "23            0.3345            0.4485             0.568            0.6355   \n",
       "6             0.2595            0.4980             0.578            0.6920   \n",
       "7             0.3790            0.5200             0.587            0.6990   \n",
       "12            0.1785            0.3995             0.540            0.6575   \n",
       "\n",
       "    categoricaltopk6  \n",
       "24            0.6030  \n",
       "23            0.7190  \n",
       "6             0.7920  \n",
       "7             0.8060  \n",
       "12            0.7715  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = df_full.sort_values('dataset')\n",
    "#df_full['zeroonerankaccuracy'] = 1 - df_full['zeroonerankloss']\n",
    "df_full.loc[df_full['learner'] == 'FETA_DC_SHALLOW_ZERO']\n",
    "#df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_full[\"job_id\"]\n",
    "grouped = df_full.groupby(['dataset', 'learner'])\n",
    "data = []\n",
    "for name, group in grouped:\n",
    "    one_row = [name[0], str(name[1]).upper()]\n",
    "    #latex_row = [\"$ {}\".format(name[0]), \"$ {}\".format(str(name[1]).upper())]\n",
    "    std = group.std(axis=0).values\n",
    "    mean = group.mean(axis=0).values\n",
    "    if np.all(np.isnan(std)):\n",
    "        one_row.extend([\"{:.4f}\".format(m) for m in mean])\n",
    "        #latex_row.extend([\"${:.3f}$\".format(m) for m in mean]) \n",
    "    else:\n",
    "        std = [s*1e3 for s in std]\n",
    "        one_row.extend([\"{:.3f}({:.0f})\".format(m, s) for m, s in zip(mean, std)])\n",
    "        #latex_row.extend([\"$ {:.3f} \\pm {:.3f} \".format(m, s) for m, s in zip(mean, std)])\n",
    "    data.append(one_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>categoricalaccuracy</th>\n",
       "      <th>categoricaltopk2</th>\n",
       "      <th>categoricaltopk3</th>\n",
       "      <th>categoricaltopk4</th>\n",
       "      <th>categoricaltopk5</th>\n",
       "      <th>categoricaltopk6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.292(21)</td>\n",
       "      <td>0.414(18)</td>\n",
       "      <td>0.559(78)</td>\n",
       "      <td>0.647(45)</td>\n",
       "      <td>0.730(35)</td>\n",
       "      <td>0.808(11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FETA_DC_SHALLOW</td>\n",
       "      <td>0.292(7)</td>\n",
       "      <td>0.401(23)</td>\n",
       "      <td>0.507(26)</td>\n",
       "      <td>0.602(40)</td>\n",
       "      <td>0.687(32)</td>\n",
       "      <td>0.769(35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>FETA_DC_SHALLOW_ZERO</td>\n",
       "      <td>0.158(74)</td>\n",
       "      <td>0.273(83)</td>\n",
       "      <td>0.436(83)</td>\n",
       "      <td>0.538(70)</td>\n",
       "      <td>0.639(75)</td>\n",
       "      <td>0.738(83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>GENERALIZED_EXTREME_VALUE</td>\n",
       "      <td>0.218(62)</td>\n",
       "      <td>0.366(71)</td>\n",
       "      <td>0.502(18)</td>\n",
       "      <td>0.608(23)</td>\n",
       "      <td>0.685(22)</td>\n",
       "      <td>0.754(34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>MIXED_LOGIT_MODEL</td>\n",
       "      <td>0.262(7)</td>\n",
       "      <td>0.387(8)</td>\n",
       "      <td>0.465(14)</td>\n",
       "      <td>0.566(13)</td>\n",
       "      <td>0.624(10)</td>\n",
       "      <td>0.724(14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>MULTINOMIAL_LOGIT_MODEL</td>\n",
       "      <td>0.271(6)</td>\n",
       "      <td>0.387(5)</td>\n",
       "      <td>0.502(2)</td>\n",
       "      <td>0.581(18)</td>\n",
       "      <td>0.676(11)</td>\n",
       "      <td>0.786(7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>NESTED_LOGIT_MODEL</td>\n",
       "      <td>0.263(12)</td>\n",
       "      <td>0.375(5)</td>\n",
       "      <td>0.492(14)</td>\n",
       "      <td>0.601(11)</td>\n",
       "      <td>0.671(13)</td>\n",
       "      <td>0.736(24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>PAIRED_COMBINATORIAL_LOGIT</td>\n",
       "      <td>0.269(6)</td>\n",
       "      <td>0.387(6)</td>\n",
       "      <td>0.500(12)</td>\n",
       "      <td>0.595(18)</td>\n",
       "      <td>0.676(10)</td>\n",
       "      <td>0.785(6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>RANKNET_DC_SHALLOW</td>\n",
       "      <td>0.269(13)</td>\n",
       "      <td>0.436(20)</td>\n",
       "      <td>0.555(25)</td>\n",
       "      <td>0.661(14)</td>\n",
       "      <td>0.758(21)</td>\n",
       "      <td>0.831(20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUSHI_DC</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.258(4)</td>\n",
       "      <td>0.372(7)</td>\n",
       "      <td>0.480(22)</td>\n",
       "      <td>0.594(17)</td>\n",
       "      <td>0.679(13)</td>\n",
       "      <td>0.779(6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset                     learner categoricalaccuracy categoricaltopk2  \\\n",
       "0  SUSHI_DC                     FATE_DC           0.292(21)        0.414(18)   \n",
       "1  SUSHI_DC             FETA_DC_SHALLOW            0.292(7)        0.401(23)   \n",
       "2  SUSHI_DC        FETA_DC_SHALLOW_ZERO           0.158(74)        0.273(83)   \n",
       "3  SUSHI_DC   GENERALIZED_EXTREME_VALUE           0.218(62)        0.366(71)   \n",
       "4  SUSHI_DC           MIXED_LOGIT_MODEL            0.262(7)         0.387(8)   \n",
       "5  SUSHI_DC     MULTINOMIAL_LOGIT_MODEL            0.271(6)         0.387(5)   \n",
       "6  SUSHI_DC          NESTED_LOGIT_MODEL           0.263(12)         0.375(5)   \n",
       "7  SUSHI_DC  PAIRED_COMBINATORIAL_LOGIT            0.269(6)         0.387(6)   \n",
       "8  SUSHI_DC          RANKNET_DC_SHALLOW           0.269(13)        0.436(20)   \n",
       "9  SUSHI_DC                  RANKSVM_DC            0.258(4)         0.372(7)   \n",
       "\n",
       "  categoricaltopk3 categoricaltopk4 categoricaltopk5 categoricaltopk6  \n",
       "0        0.559(78)        0.647(45)        0.730(35)        0.808(11)  \n",
       "1        0.507(26)        0.602(40)        0.687(32)        0.769(35)  \n",
       "2        0.436(83)        0.538(70)        0.639(75)        0.738(83)  \n",
       "3        0.502(18)        0.608(23)        0.685(22)        0.754(34)  \n",
       "4        0.465(14)        0.566(13)        0.624(10)        0.724(14)  \n",
       "5         0.502(2)        0.581(18)        0.676(11)         0.786(7)  \n",
       "6        0.492(14)        0.601(11)        0.671(13)        0.736(24)  \n",
       "7        0.500(12)        0.595(18)        0.676(10)         0.785(6)  \n",
       "8        0.555(25)        0.661(14)        0.758(21)        0.831(20)  \n",
       "9        0.480(22)        0.594(17)        0.679(13)         0.779(6)  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=columns[1:])\n",
    "df.sort_values(by='dataset')\n",
    "df_path = os.path.join(DIR_PATH, 'results' , DATASET+'.csv')\n",
    "df.to_csv(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_ranker(sub_df):\n",
    "    remove_ranker = None\n",
    "    print(sub_df)\n",
    "    if len(sub_df)==2:\n",
    "        sub_df = sub_df[:,0:2]\n",
    "        val1 = [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", sub_df[0][1])]\n",
    "        val2 = [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", sub_df[1][1])]\n",
    "        val1 = val1[0] if len(val1)==1 else val1[0] - val1[1]*1e-3\n",
    "        val2 = val2[0] if len(val2)==1 else val2[0] - val2[1]*1e-3\n",
    "        if val1 < val2 :\n",
    "            remove_ranker = sub_df[0][0]\n",
    "        else:\n",
    "            remove_ranker = sub_df[1][0]\n",
    "    return remove_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[['FATE_DC' '0.231(12)' '0.368(19)' '0.477(24)' '0.574(30)' '0.656(40)'\n",
      "  '0.735(44)']\n",
      " ['FATE_DC_SHALLOW' '0.2172' '0.3366' '0.4558' '0.5591' '0.6493' '0.7331']]\n",
      "name Y_2007_N_10\n",
      "['learner', 'categoricalaccuracy', 'categoricaltopk2', 'categoricaltopk3', 'categoricaltopk4', 'categoricaltopk5', 'categoricaltopk6']\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "learner & categoricalaccuracy & categoricaltopk2 & categoricaltopk3 & categoricaltopk4 & categoricaltopk5 & categoricaltopk6\\\\\n",
      "\\midrule\n",
      "RANKSVM\\_DC & 0.298(14) & 0.446(17) & 0.566(12) & 0.666(6) & 0.751(3) & 0.821(5)\\\\\n",
      "RANKNET\\_DC & 0.2214 & 0.3671 & 0.4831 & 0.5869 & 0.6803 & 0.7690\\\\\n",
      "MULTINOMIAL\\_LOGIT\\_MODEL & 0.287(16) & 0.442(15) & 0.566(14) & 0.668(11) & 0.753(8) & 0.818(8)\\\\\n",
      "NESTED\\_LOGIT\\_MODEL & 0.301(21) & 0.458(18) & 0.576(17) & 0.677(12) & 0.758(14) & 0.822(10)\\\\\n",
      "GENERALIZED\\_EXTREME\\_VALUE & 0.295(20) & 0.449(19) & 0.566(15) & 0.667(11) & 0.752(7) & 0.815(8)\\\\\n",
      "PAIRED\\_COMBINATORIAL\\_LOGIT & 0.290(20) & 0.442(18) & 0.564(17) & 0.668(12) & 0.750(7) & 0.819(6)\\\\\n",
      "MIXED\\_LOGIT\\_MODEL & 0.246(16) & 0.380(20) & 0.492(18) & 0.588(18) & 0.679(19) & 0.762(15)\\\\\n",
      "FATE\\_DC & 0.231(12) & 0.368(19) & 0.477(24) & 0.574(30) & 0.656(40) & 0.735(44)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "[['FETA_DC_ZERO' '0.344(114)' '0.558(138)' '0.732(119)' '0.874(75)'\n",
      "  '1.000(0)' '1.000(0)']]\n",
      "[['FATE_DC' '0.348(13)' '0.575(7)' '0.747(3)' '0.886(6)' '1.000(0)'\n",
      "  '1.000(0)']\n",
      " ['FATE_DC_SHALLOW' '0.417(9)' '0.635(12)' '0.796(11)' '0.910(7)'\n",
      "  '1.000(0)' '1.000(0)']]\n",
      "name Y_2007_N_5\n",
      "['learner', 'categoricalaccuracy', 'categoricaltopk2', 'categoricaltopk3', 'categoricaltopk4', 'categoricaltopk5', 'categoricaltopk6']\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "learner & categoricalaccuracy & categoricaltopk2 & categoricaltopk3 & categoricaltopk4 & categoricaltopk5 & categoricaltopk6\\\\\n",
      "\\midrule\n",
      "RANKSVM\\_DC & 0.427(13) & 0.651(5) & 0.807(3) & 0.916(6) & 1.000(0) & 1.000(0)\\\\\n",
      "MULTINOMIAL\\_LOGIT\\_MODEL & 0.420(18) & 0.646(13) & 0.801(7) & 0.913(4) & 1.000(0) & 1.000(0)\\\\\n",
      "NESTED\\_LOGIT\\_MODEL & 0.429(11) & 0.654(6) & 0.807(4) & 0.918(4) & 1.000(0) & 1.000(0)\\\\\n",
      "GENERALIZED\\_EXTREME\\_VALUE & 0.428(14) & 0.658(5) & 0.812(4) & 0.918(5) & 1.000(0) & 1.000(0)\\\\\n",
      "PAIRED\\_COMBINATORIAL\\_LOGIT & 0.429(15) & 0.653(6) & 0.804(6) & 0.915(5) & 1.000(0) & 1.000(0)\\\\\n",
      "MIXED\\_LOGIT\\_MODEL & 0.428(10) & 0.650(5) & 0.801(8) & 0.913(8) & 1.000(0) & 1.000(0)\\\\\n",
      "FETA\\_DC\\_ZERO & 0.344(114) & 0.558(138) & 0.732(119) & 0.874(75) & 1.000(0) & 1.000(0)\\\\\n",
      "FATE\\_DC\\_SHALLOW & 0.417(9) & 0.635(12) & 0.796(11) & 0.910(7) & 1.000(0) & 1.000(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "[['FETA_DC_ZERO' '0.363(49)' '0.549(44)' '0.674(40)' '0.772(24)'\n",
      "  '0.845(18)' '0.906(15)']]\n",
      "[['FATE_DC' '0.384(33)' '0.543(21)' '0.666(27)' '0.772(25)' '0.859(23)'\n",
      "  '0.911(21)']\n",
      " ['FATE_DC_SHALLOW' '0.384(37)' '0.554(41)' '0.683(42)' '0.783(33)'\n",
      "  '0.862(25)' '0.911(26)']]\n",
      "name Y_2008_N_10\n",
      "['learner', 'categoricalaccuracy', 'categoricaltopk2', 'categoricaltopk3', 'categoricaltopk4', 'categoricaltopk5', 'categoricaltopk6']\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "learner & categoricalaccuracy & categoricaltopk2 & categoricaltopk3 & categoricaltopk4 & categoricaltopk5 & categoricaltopk6\\\\\n",
      "\\midrule\n",
      "pariwisesvm & 0.428(17) & 0.610(34) & 0.741(41) & 0.818(31) & 0.879(29) & 0.926(21)\\\\\n",
      "ranknetdc & 0.281(50) & 0.451(77) & 0.583(83) & 0.681(85) & 0.763(77) & 0.835(70)\\\\\n",
      "mnl & 0.429(40) & 0.600(28) & 0.725(33) & 0.812(25) & 0.875(20) & 0.926(17)\\\\\n",
      "nlm & 0.415(28) & 0.596(28) & 0.723(30) & 0.801(31) & 0.866(24) & 0.915(21)\\\\\n",
      "gev & 0.413(30) & 0.591(29) & 0.720(27) & 0.805(18) & 0.874(20) & 0.923(16)\\\\\n",
      "pcl & 0.412(30) & 0.599(29) & 0.726(30) & 0.802(23) & 0.873(24) & 0.921(19)\\\\\n",
      "mlm & 0.428(37) & 0.602(35) & 0.714(49) & 0.801(38) & 0.858(36) & 0.908(21)\\\\\n",
      "fate & 0.384(33) & 0.543(21) & 0.666(27) & 0.772(25) & 0.859(23) & 0.911(21)\\\\\n",
      "feta & 0.363(49) & 0.549(44) & 0.674(40) & 0.772(24) & 0.845(18) & 0.906(15)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "[['FETA_DC_ZERO' '0.533(41)' '0.770(34)' '0.903(23)' '0.963(15)'\n",
      "  '1.000(0)' '1.000(0)']]\n",
      "[['FATE_DC' '0.509(83)' '0.743(71)' '0.887(36)' '0.959(12)' '1.000(0)'\n",
      "  '1.000(0)']\n",
      " ['FATE_DC_SHALLOW' '0.562(34)' '0.776(32)' '0.903(22)' '0.965(12)'\n",
      "  '1.000(0)' '1.000(0)']]\n",
      "name Y_2008_N_5\n",
      "['learner', 'categoricalaccuracy', 'categoricaltopk2', 'categoricaltopk3', 'categoricaltopk4', 'categoricaltopk5', 'categoricaltopk6']\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "learner & categoricalaccuracy & categoricaltopk2 & categoricaltopk3 & categoricaltopk4 & categoricaltopk5 & categoricaltopk6\\\\\n",
      "\\midrule\n",
      "pariwisesvm & 0.569(46) & 0.786(30) & 0.908(23) & 0.969(11) & 1.000(0) & 1.000(0)\\\\\n",
      "ranknetdc & 0.458(28) & 0.683(27) & 0.842(25) & 0.936(15) & 1.000(0) & 1.000(0)\\\\\n",
      "mnl & 0.568(26) & 0.788(20) & 0.904(14) & 0.967(8) & 1.000(0) & 1.000(0)\\\\\n",
      "nlm & 0.566(34) & 0.790(30) & 0.911(24) & 0.969(9) & 1.000(0) & 1.000(0)\\\\\n",
      "gev & 0.568(21) & 0.786(23) & 0.910(21) & 0.968(10) & 1.000(0) & 1.000(0)\\\\\n",
      "pcl & 0.566(19) & 0.783(12) & 0.903(13) & 0.966(8) & 1.000(0) & 1.000(0)\\\\\n",
      "mlm & 0.572(25) & 0.781(24) & 0.902(17) & 0.963(11) & 1.000(0) & 1.000(0)\\\\\n",
      "fate & 0.533(41) & 0.770(34) & 0.903(23) & 0.963(15) & 1.000(0) & 1.000(0)\\\\\n",
      "feta & 0.562(34) & 0.776(32) & 0.903(22) & 0.965(12) & 1.000(0) & 1.000(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from tabulate import tabulate\n",
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    custom_dict = {\"RANKSVM_DC\":0, \"RANKNET_DC\":1, 'MULTINOMIAL_LOGIT_MODEL':2, 'NESTED_LOGIT_MODEL':3, 'GENERALIZED_EXTREME_VALUE':4, \n",
    "                   'PAIRED_COMBINATORIAL_LOGIT':5, \"MIXED_LOGIT_MODEL\":6, \"FATE_DC\":7, \"FETA_DC\":8, \"FETA_DC_ZERO\":9}\n",
    "    group['rank'] = group['learner'].map(custom_dict)\n",
    "    group.sort_values(by='rank', inplace=True)\n",
    "    del group[\"dataset\"]\n",
    "    del group['rank']\n",
    "    remove_rankers = []\n",
    "    sub_df = group[group['learner'].str.contains(\"FETA\")].as_matrix()\n",
    "    r1 = remove_ranker(sub_df)\n",
    "    sub_df = group[group['learner'].str.contains(\"FATE\")].as_matrix()\n",
    "    r2 = remove_ranker(sub_df)\n",
    "    remove_rankers.append(r1)\n",
    "    remove_rankers.append(r2)\n",
    "    \n",
    "    group = group[~group['learner'].isin(remove_rankers)]\n",
    "    if len(group)==9:\n",
    "        group['learner'] = [\"pariwisesvm\", \"ranknetdc\", \"mnl\", \"nlm\", \"gev\", \"pcl\", \"mlm\", \"fate\", \"feta\"]\n",
    "    print(\"name {}\".format(name))\n",
    "    print(list(group.columns))\n",
    "    latex_code = group.to_latex(index = False)\n",
    "    latex_code = latex_code.replace(' ',\"\")\n",
    "    latex_code = latex_code.replace('&',\" & \")\n",
    "    print(latex_code)\n",
    "#df.T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = os.path.join(DIR_PATH, 'results' , \"discrete_choice.csv\")\n",
    "\n",
    "if not os.path.isfile(df_path):\n",
    "    dataFrame = df\n",
    "else:\n",
    "    dataFrame = pd.read_csv(df_path, index_col=0)\n",
    "    dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "dataFrame\n",
    "dataFrame.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)\n",
    "\n",
    "X_train = np.arange(40).reshape(4,5,2)\n",
    "\n",
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "self.schema = 'pymc3'\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "fold_id = 1\n",
    "cluster_id=1234\n",
    "self.fetch_job_arguments(cluster_id=cluster_id)\n",
    "self.init_connection(cursor_factory=None)\n",
    "job_desc = dict(self.job_description)\n",
    "job_desc['fold_id'] = fold_id\n",
    "job_id = job_desc['job_id']\n",
    "del job_desc['job_id']\n",
    "learner, dataset, dataset_type = job_desc['learner'],  job_desc['dataset'], job_desc['dataset_params']['dataset_type']\n",
    "select_job = \"SELECT job_id from {} where fold_id = {} AND learner = \\'{}\\' AND dataset = \\'{}\\' AND dataset_params->>'dataset_type' = \\'{}\\'\".format(\n",
    "    avail_jobs, fold_id, learner, dataset, dataset_type)\n",
    "self.cursor_db.execute(select_job)\n",
    "\n",
    "if self.cursor_db.rowcount == 0:\n",
    "    keys = list(job_desc.keys())\n",
    "    columns = ', '.join(keys)\n",
    "    index = keys.index('fold_id')\n",
    "    keys[index] = str(fold_id)\n",
    "    values_str = ', '.join(keys)\n",
    "    insert_job = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "    print(\"Inserting job with new fold: {}\".format(insert_job))\n",
    "    self.cursor_db.execute(insert_job)    \n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "print(\"Job {} with fold id {} updated/inserted\".format(fold_id, job_id))\n",
    "start = datetime.now()\n",
    "update_job = \"\"\"UPDATE {} set job_allocated_time = %s WHERE job_id = %s\"\"\".format(avail_jobs)\n",
    "self.cursor_db.execute(update_job, (start, job_id))\n",
    "select_job = \"\"\"SELECT * FROM {0} WHERE {0}.job_id = {1} AND {0}.interrupted = {2} FOR UPDATE\"\"\".format(\n",
    "    running_jobs, job_id, True)\n",
    "self.cursor_db.execute(select_job)\n",
    "count_ = len(self.cursor_db.fetchall())\n",
    "if count_ == 0:\n",
    "    insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    self.cursor_db.execute(insert_job)\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "else:\n",
    "    print(\"Job with job_id {} present in the updating and row locked\".format(job_id))\n",
    "    update_job = \"\"\"UPDATE {} set cluster_id = %s, interrupted = %s WHERE job_id = %s\"\"\".format(\n",
    "        running_jobs)\n",
    "    self.cursor_db.execute(update_job, (cluster_id, 'FALSE', job_id))\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unique_max_occurring'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"UNIQUE_MAX_OCCURRING\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
