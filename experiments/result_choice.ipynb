{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from csrank.util import setup_logging\n",
    "from experiments.util import lp_metric_dict\n",
    "import numpy as np\n",
    "from experiments.dbconnection import DBConnector\n",
    "from experiments.constants import CHOICE_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results.log')\n",
    "setup_logging(log_path=log_path)\n",
    "logger = logging.getLogger('ResultParsing')\n",
    "learning_problem = \"choice_function\"\n",
    "schema = \"choice_functions\"\n",
    "datasets = ['synthetic_choice', 'mnist_choice']\n",
    "keys = list(lp_metric_dict[learning_problem].keys())\n",
    "keys[-1] = keys[-1].format(6)\n",
    "metrics = ', '.join([x.lower() for x in keys])\n",
    "models = ['FETA-Net', 'FATE-Net', 'RankNet-Choice', 'PairwiseSVM', 'GeneralizedLinearModel', \"RandomGuessing\"]\n",
    "Dlower = [d.upper() for d in CHOICE_FUNCTIONS]\n",
    "models_dict = dict(zip(Dlower, models))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "#update_result = \"UPDATE results.discrete_choice set cluster_id = %s, CategoricalAccuracy = %s, CategoricalTopK2 = %s, CategoricalTopK3 = %s, CategoricalTopK4 = %s, CategoricalTopK5 = %s, CategoricalTopK6 = %s  where job_id= %s\"\n",
    "values = ('22412', '0.0636', '0.1329', '0.2200', '0.3250', '0.4517', '0.5950', '1002')\n",
    "self.init_connection()\n",
    "self.cursor_db.execute(update_result, tuple(values))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>f1score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>subset01loss</th>\n",
       "      <th>hammingloss</th>\n",
       "      <th>informedness</th>\n",
       "      <th>aucscore</th>\n",
       "      <th>averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FATE_CHOICE</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.4397</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8668</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.5876</td>\n",
       "      <td>0.6060</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.5052</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.7367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset        learner  f1score  precision  recall  subset01loss  \\\n",
       "0   PARETO    FATE_CHOICE   0.9250     0.9438  0.9241        0.4397   \n",
       "21  PARETO  RANDOM_CHOICE   0.2315     0.1332  1.0000        1.0000   \n",
       "20  PARETO     GLM_CHOICE   0.5876     0.6060  0.7402        0.9544   \n",
       "19  PARETO  RANDOM_CHOICE   0.2318     0.1334  1.0000        1.0000   \n",
       "18  PARETO     GLM_CHOICE   0.4924     0.5052  0.6432        0.9830   \n",
       "\n",
       "    hammingloss  informedness  aucscore  averageprecisionscore  \n",
       "0        0.0212        0.9135    0.9972                 0.9884  \n",
       "21       0.8668        0.0000    0.5000                 0.1332  \n",
       "20       0.1302        0.6377    0.9560                 0.8649  \n",
       "19       0.8666        0.0000    0.5000                 0.1334  \n",
       "18       0.1696        0.5095    0.8673                 0.7367  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results_for_dataset(DATASET, del_jid = True):\n",
    "    config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "    results_table = 'results.{}'.format(learning_problem)\n",
    "    schema = 'choice_functions'\n",
    "    start = 3\n",
    "    select_jobs = \"SELECT learner_params, dataset_params, hp_ranges, {0}.job_id, dataset, learner, {3} from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset=\\'{2}\\'\"\n",
    "    self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "    self.init_connection()\n",
    "    avail_jobs = \"{}.avail_jobs\".format(schema)\n",
    "    select_st = select_jobs.format(results_table, avail_jobs, DATASET, metrics)\n",
    "    #print(select_st)\n",
    "    self.cursor_db.execute(select_st)\n",
    "    data = []\n",
    "    for job in self.cursor_db.fetchall():\n",
    "        job = dict(job)\n",
    "        if job['learner'] in job['hp_ranges'].keys():\n",
    "            n_hidden = job['hp_ranges'][job['learner']].get(\"n_hidden\", [])\n",
    "            if job['hp_ranges'][job['learner']].get(\"n_hidden_set_layers\", None)==[1,8]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "            elif n_hidden==[1,4] or n_hidden==[1,5]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "\n",
    "        if job['learner_params'].get(\"add_zeroth_order_model\", False):\n",
    "            job['learner'] = job['learner']+'_zero'\n",
    "        if \"letor\" in job['dataset']:\n",
    "            job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "        elif \"sushi\" in job['dataset']:\n",
    "            job['dataset'] =  job['dataset']\n",
    "        else:\n",
    "            job['dataset'] = job['dataset_params']['dataset_type']\n",
    "        job['learner'] = job['learner'].upper()\n",
    "        job['dataset'] = job['dataset'].upper()\n",
    "        values = list(job.values())\n",
    "        keys = list(job.keys())\n",
    "        columns = keys[start:]\n",
    "        vals = values[start:]\n",
    "        \n",
    "        data.append(vals)\n",
    "    df_full = pd.DataFrame(data, columns=columns)\n",
    "    df_full = df_full.sort_values('dataset')\n",
    "    if del_jid:\n",
    "        del df_full['job_id']\n",
    "    columns = list(df_full.columns)\n",
    "    return df_full, columns\n",
    "df, cols = get_results_for_dataset(datasets[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dfs(DATASET, latex_row=False):\n",
    "    df_full, columns = get_results_for_dataset(DATASET)\n",
    "    data = []\n",
    "    dataf = []\n",
    "    for dataset, dgroup in df_full.groupby(['dataset']):\n",
    "        max_feta = -100\n",
    "        max_fate = -100\n",
    "        max_ranknet = -100\n",
    "        feta_r = []\n",
    "        fate_r = []\n",
    "        ranknet_r = []\n",
    "        for learner, group in dgroup.groupby(['learner']):\n",
    "            one_row = [dataset.lower().title(), learner]\n",
    "            std = np.around(group.std(axis=0).values,3)\n",
    "            mean = np.around(group.mean(axis=0).values,3)\n",
    "            if np.all(np.isnan(std)):\n",
    "                one_row.extend([\"{:.4f}\".format(m) for m in mean])\n",
    "                #latex_row.extend([\"${:.3f}$\".format(m) for m in mean]) \n",
    "            else:\n",
    "                std_err = [s for s in std]\n",
    "                #std_err = [s/np.sqrt(len(group)) for s in std]\n",
    "                #one_row.extend([m for m in mean])\n",
    "                #one_row.extend([se for se in std_err])\n",
    "                #one_row.extend(mean)\n",
    "                if latex_row:\n",
    "                    one_row.extend([\"{:.3f}({:.0f})\".format(m, s*1e3) for m, s in zip(mean, std)])\n",
    "                else:\n",
    "                    one_row.extend([\"{:.3f}±{:.3f}\".format(m, s) for m, s in zip(mean, std)])\n",
    "            if \"FETA\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_feta = mean[0] - std[0]\n",
    "                    feta_r = one_row\n",
    "                    feta_r[1] = models_dict[\"FETA_CHOICE\"]\n",
    "            elif \"FATE\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_fate = mean[0] - std[0]\n",
    "                    fate_r = one_row\n",
    "                    fate_r[1] = models_dict[\"FATE_CHOICE\"]\n",
    "            elif \"RANKNET\" in str(learner):\n",
    "                if max_ranknet < mean[0] - std[0]:\n",
    "                    max_ranknet = mean[0] - std[0]\n",
    "                    ranknet_r = one_row\n",
    "                    ranknet_r[1] = models_dict[\"RANKNET_CHOICE\"]\n",
    "            else:\n",
    "                one_row[1] = models_dict[one_row[1]]\n",
    "                data.append(one_row)\n",
    "        if len(feta_r)!=0:\n",
    "            data.append(feta_r)\n",
    "        if len(fate_r)!=0:\n",
    "            data.append(fate_r)\n",
    "        if len(ranknet_r)!=0:\n",
    "            data.append(ranknet_r)\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i].title()\n",
    "        if columns[i] == 'Learner':\n",
    "            columns[i] = \"ChoiceModel\"\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.sort_values(by='Dataset')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ChoiceModel</th>\n",
       "      <th>F1Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Subset01Loss</th>\n",
       "      <th>Hammingloss</th>\n",
       "      <th>Informedness</th>\n",
       "      <th>Aucscore</th>\n",
       "      <th>Averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mode</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.999±0.001</td>\n",
       "      <td>0.997±0.000</td>\n",
       "      <td>0.557±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.497±0.004</td>\n",
       "      <td>0.561±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mode</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.997±0.000</td>\n",
       "      <td>0.558±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mode</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.999±0.002</td>\n",
       "      <td>0.997±0.000</td>\n",
       "      <td>0.557±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.509±0.006</td>\n",
       "      <td>0.569±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mode</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.976±0.000</td>\n",
       "      <td>0.980±0.004</td>\n",
       "      <td>0.979±0.003</td>\n",
       "      <td>0.118±0.003</td>\n",
       "      <td>0.022±0.000</td>\n",
       "      <td>0.960±0.001</td>\n",
       "      <td>0.991±0.001</td>\n",
       "      <td>0.990±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unique</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.595±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.532±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unique</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.595±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unique</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.595±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.532±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.595±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.532±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.140±0.281</td>\n",
       "      <td>0.101±0.202</td>\n",
       "      <td>0.250±0.500</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.452±0.095</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset             ChoiceModel      F1Score    Precision       Recall  \\\n",
       "0    Mode  GeneralizedLinearModel  0.597±0.000  0.442±0.000  0.999±0.001   \n",
       "1    Mode          RandomGuessing  0.597±0.000  0.442±0.000  1.000±0.000   \n",
       "2    Mode             PairwiseSVM  0.597±0.000  0.442±0.000  0.999±0.002   \n",
       "3    Mode                FATE-Net  0.976±0.000  0.980±0.004  0.979±0.003   \n",
       "4  Unique  GeneralizedLinearModel  0.562±0.000  0.405±0.000  1.000±0.000   \n",
       "5  Unique          RandomGuessing  0.562±0.000  0.405±0.000  1.000±0.000   \n",
       "6  Unique             PairwiseSVM  0.562±0.000  0.405±0.000  1.000±0.000   \n",
       "7  Unique                FETA-Net  0.562±0.000  0.405±0.000  1.000±0.000   \n",
       "8  Unique                FATE-Net  0.140±0.281  0.101±0.202  0.250±0.500   \n",
       "\n",
       "  Subset01Loss  Hammingloss Informedness     Aucscore Averageprecisionscore  \n",
       "0  0.997±0.000  0.557±0.000  0.000±0.000  0.497±0.004           0.561±0.002  \n",
       "1  0.997±0.000  0.558±0.000  0.000±0.000  0.500±0.000           0.442±0.000  \n",
       "2  0.997±0.000  0.557±0.000  0.000±0.000  0.509±0.006           0.569±0.004  \n",
       "3  0.118±0.003  0.022±0.000  0.960±0.001  0.991±0.001           0.990±0.002  \n",
       "4  1.000±0.000  0.595±0.000  0.000±0.000  0.500±0.001           0.532±0.001  \n",
       "5  1.000±0.000  0.595±0.000  0.000±0.000  0.500±0.000           0.405±0.000  \n",
       "6  1.000±0.000  0.595±0.000  0.000±0.000  0.500±0.000           0.532±0.000  \n",
       "7  1.000±0.000  0.595±0.000  0.000±0.000  0.500±0.001           0.532±0.000  \n",
       "8  1.000±0.000  0.452±0.095  0.000±0.000  0.500±0.000           0.405±0.000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    df = create_combined_dfs(dataset)\n",
    "    df_path = os.path.join(DIR_PATH, 'detailedresults' , dataset.split('_choice')[0].title()+'.csv')\n",
    "    df.to_csv(df_path, index=False, encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ChoiceModel</th>\n",
       "      <th>F1Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Subset01Loss</th>\n",
       "      <th>Hammingloss</th>\n",
       "      <th>Informedness</th>\n",
       "      <th>Aucscore</th>\n",
       "      <th>Averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mode</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.597(0)</td>\n",
       "      <td>0.442(0)</td>\n",
       "      <td>0.999(1)</td>\n",
       "      <td>0.997(0)</td>\n",
       "      <td>0.557(0)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.497(4)</td>\n",
       "      <td>0.561(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mode</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.597(0)</td>\n",
       "      <td>0.442(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>0.997(0)</td>\n",
       "      <td>0.558(0)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.500(0)</td>\n",
       "      <td>0.442(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mode</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.597(0)</td>\n",
       "      <td>0.442(0)</td>\n",
       "      <td>0.999(2)</td>\n",
       "      <td>0.997(0)</td>\n",
       "      <td>0.557(0)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.509(6)</td>\n",
       "      <td>0.569(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mode</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.976(0)</td>\n",
       "      <td>0.980(4)</td>\n",
       "      <td>0.979(3)</td>\n",
       "      <td>0.118(3)</td>\n",
       "      <td>0.022(0)</td>\n",
       "      <td>0.960(1)</td>\n",
       "      <td>0.991(1)</td>\n",
       "      <td>0.990(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unique</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.562(0)</td>\n",
       "      <td>0.405(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>0.595(0)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.500(1)</td>\n",
       "      <td>0.532(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unique</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.562(0)</td>\n",
       "      <td>0.405(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>0.595(0)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.500(0)</td>\n",
       "      <td>0.405(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unique</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.562(0)</td>\n",
       "      <td>0.405(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>0.595(0)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.500(0)</td>\n",
       "      <td>0.532(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.562(0)</td>\n",
       "      <td>0.405(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>0.595(0)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.500(1)</td>\n",
       "      <td>0.532(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.140(281)</td>\n",
       "      <td>0.101(202)</td>\n",
       "      <td>0.250(500)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>0.452(95)</td>\n",
       "      <td>0.000(0)</td>\n",
       "      <td>0.500(0)</td>\n",
       "      <td>0.405(0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset             ChoiceModel     F1Score   Precision      Recall  \\\n",
       "0    Mode  GeneralizedLinearModel    0.597(0)    0.442(0)    0.999(1)   \n",
       "1    Mode          RandomGuessing    0.597(0)    0.442(0)    1.000(0)   \n",
       "2    Mode             PairwiseSVM    0.597(0)    0.442(0)    0.999(2)   \n",
       "3    Mode                FATE-Net    0.976(0)    0.980(4)    0.979(3)   \n",
       "4  Unique  GeneralizedLinearModel    0.562(0)    0.405(0)    1.000(0)   \n",
       "5  Unique          RandomGuessing    0.562(0)    0.405(0)    1.000(0)   \n",
       "6  Unique             PairwiseSVM    0.562(0)    0.405(0)    1.000(0)   \n",
       "7  Unique                FETA-Net    0.562(0)    0.405(0)    1.000(0)   \n",
       "8  Unique                FATE-Net  0.140(281)  0.101(202)  0.250(500)   \n",
       "\n",
       "  Subset01Loss Hammingloss Informedness  Aucscore Averageprecisionscore  \n",
       "0     0.997(0)    0.557(0)     0.000(0)  0.497(4)              0.561(2)  \n",
       "1     0.997(0)    0.558(0)     0.000(0)  0.500(0)              0.442(0)  \n",
       "2     0.997(0)    0.557(0)     0.000(0)  0.509(6)              0.569(4)  \n",
       "3     0.118(3)    0.022(0)     0.960(1)  0.991(1)              0.990(2)  \n",
       "4     1.000(0)    0.595(0)     0.000(0)  0.500(1)              0.532(1)  \n",
       "5     1.000(0)    0.595(0)     0.000(0)  0.500(0)              0.405(0)  \n",
       "6     1.000(0)    0.595(0)     0.000(0)  0.500(0)              0.532(0)  \n",
       "7     1.000(0)    0.595(0)     0.000(0)  0.500(1)              0.532(0)  \n",
       "8     1.000(0)   0.452(95)     0.000(0)  0.500(0)              0.405(0)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = datasets[1]\n",
    "df = create_combined_dfs(DATASET, latex_row=True)\n",
    "df.sort_values(by='Dataset')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_ranker(sub_df):\n",
    "    remove_ranker = None\n",
    "    if len(sub_df)==2:\n",
    "        sub_df = sub_df[:,1:3]\n",
    "        val1 = [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", sub_df[0][1])]\n",
    "        val2 = [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", sub_df[1][1])]\n",
    "        val1 = val1[0] if len(val1)==1 else val1[0] - val1[1]*1e-3\n",
    "        val2 = val2[0] if len(val2)==1 else val2[0] - val2[1]*1e-3\n",
    "        if val1 < val2 :\n",
    "            remove_ranker = sub_df[0][0]\n",
    "        else:\n",
    "            remove_ranker = sub_df[1][0]\n",
    "    return remove_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    return [vals[0], vals[0] - vals[1]*1e-3]\n",
    "def mark_best(df):\n",
    "    for col in list(df.columns)[1:]:\n",
    "        values_str = df[['ChoiceModel',col]].as_matrix()\n",
    "        values = np.array([get_val(val[1])for val in values_str])\n",
    "        maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0]\n",
    "        for ind in maxi:\n",
    "            values_str[ind] = [values_str[ind][0], \"bfseries {}\".format(values_str[ind][1])]\n",
    "        df['ChoiceModel'] = values_str[:,0]\n",
    "        df[col] = values_str[:,1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name Mode\n",
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "ChoiceModel & F1Score & Precision & Recall & Subset01Loss & Hammingloss & Informedness & Aucscore & Averageprecisionscore\\\\\n",
      "\\midrule\n",
      "\\fate & \\bfseries 0.976(0) & \\bfseries 0.980(4) & 0.979(3) & 0.118(3) & 0.022(0) & \\bfseries 0.960(1) & \\bfseries 0.991(1) & \\bfseries 0.990(2)\\\\\n",
      "\\pairwisesvm & 0.597(0) & 0.442(0) & 0.999(2) & \\bfseries 0.997(0) & 0.557(0) & 0.000(0) & 0.509(6) & 0.569(4)\\\\\n",
      "\\glm & 0.597(0) & 0.442(0) & 0.999(1) & \\bfseries 0.997(0) & 0.557(0) & 0.000(0) & 0.497(4) & 0.561(2)\\\\\n",
      "\\random & 0.597(0) & 0.442(0) & \\bfseries 1.000(0) & \\bfseries 0.997(0) & \\bfseries 0.558(0) & 0.000(0) & 0.500(0) & 0.442(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "name Unique\n",
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "ChoiceModel & F1Score & Precision & Recall & Subset01Loss & Hammingloss & Informedness & Aucscore & Averageprecisionscore\\\\\n",
      "\\midrule\n",
      "\\feta & \\bfseries 0.562(0) & \\bfseries 0.405(0) & \\bfseries 1.000(0) & \\bfseries 1.000(0) & \\bfseries 0.595(0) & \\bfseries 0.000(0) & \\bfseries 0.500(1) & \\bfseries 0.532(0)\\\\\n",
      "\\fate & 0.140(281) & 0.101(202) & 0.250(500) & \\bfseries 1.000(0) & 0.452(95) & \\bfseries 0.000(0) & \\bfseries 0.500(0) & 0.405(0)\\\\\n",
      "\\pairwisesvm & \\bfseries 0.562(0) & \\bfseries 0.405(0) & \\bfseries 1.000(0) & \\bfseries 1.000(0) & \\bfseries 0.595(0) & \\bfseries 0.000(0) & \\bfseries 0.500(0) & \\bfseries 0.532(0)\\\\\n",
      "\\glm & \\bfseries 0.562(0) & \\bfseries 0.405(0) & \\bfseries 1.000(0) & \\bfseries 1.000(0) & \\bfseries 0.595(0) & \\bfseries 0.000(0) & \\bfseries 0.500(1) & \\bfseries 0.532(1)\\\\\n",
      "\\random & \\bfseries 0.562(0) & \\bfseries 0.405(0) & \\bfseries 1.000(0) & \\bfseries 1.000(0) & \\bfseries 0.595(0) & \\bfseries 0.000(0) & \\bfseries 0.500(0) & 0.405(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from tabulate import tabulate\n",
    "import string\n",
    "grouped = df.groupby(['Dataset'])\n",
    "for name, group in grouped:\n",
    "    custom_dict = dict()\n",
    "    for i, m in enumerate(models):\n",
    "        custom_dict[m] = i\n",
    "    group['rank'] = group['ChoiceModel'].map(custom_dict)\n",
    "    group.sort_values(by='rank', inplace=True)\n",
    "    del group[\"Dataset\"]\n",
    "    del group['rank']\n",
    "    group = mark_best(group)\n",
    "    group['ChoiceModel'].replace(to_replace=['GeneralizedLinearModel'], value='glm',inplace=True)\n",
    "    group['ChoiceModel'].replace(to_replace=['FATE-Net'], value='fate',inplace=True)\n",
    "    group['ChoiceModel'].replace(to_replace=['FETA-Net'], value='feta',inplace=True)\n",
    "    group['ChoiceModel'].replace(to_replace=['RankNet-Choice'], value='ranknet',inplace=True)\n",
    "    group['ChoiceModel'].replace(to_replace=['PairwiseSVM'], value='pairwisesvm',inplace=True)\n",
    "    group['ChoiceModel'].replace(to_replace=['RandomGuessing'], value='random',inplace=True)\n",
    "    print(\"name {}\".format(name))\n",
    "    latex_code = group.to_latex(index = False)\n",
    "    latex_code = latex_code.replace(' ',\"\")\n",
    "    latex_code = latex_code.replace('&',\" & \")\n",
    "    latex_code = str(latex_code)\n",
    "    for learner in group['ChoiceModel']:\n",
    "        latex_code = latex_code.replace(learner, \"\\\\{}\".format(learner))\n",
    "    latex_code = latex_code.replace(\"bfseries\", \"\\\\{} \".format(\"bfseries\"))\n",
    "    #latex_code = latex_code.replace(\"0.\", \".\")\n",
    "\n",
    "    print(latex_code)\n",
    "#df.T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = os.path.join(DIR_PATH, 'results' , \"discrete_choice.csv\")\n",
    "\n",
    "if not os.path.isfile(df_path):\n",
    "    dataFrame = df\n",
    "else:\n",
    "    dataFrame = pd.read_csv(df_path, index_col=0)\n",
    "    dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "dataFrame\n",
    "dataFrame.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)\n",
    "\n",
    "X_train = np.arange(40).reshape(4,5,2)\n",
    "\n",
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "self.schema = 'pymc3'\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "fold_id = 1\n",
    "cluster_id=1234\n",
    "self.fetch_job_arguments(cluster_id=cluster_id)\n",
    "self.init_connection(cursor_factory=None)\n",
    "job_desc = dict(self.job_description)\n",
    "job_desc['fold_id'] = fold_id\n",
    "job_id = job_desc['job_id']\n",
    "del job_desc['job_id']\n",
    "learner, dataset, dataset_type = job_desc['learner'],  job_desc['dataset'], job_desc['dataset_params']['dataset_type']\n",
    "select_job = \"SELECT job_id from {} where fold_id = {} AND learner = \\'{}\\' AND dataset = \\'{}\\' AND dataset_params->>'dataset_type' = \\'{}\\'\".format(\n",
    "    avail_jobs, fold_id, learner, dataset, dataset_type)\n",
    "self.cursor_db.execute(select_job)\n",
    "\n",
    "if self.cursor_db.rowcount == 0:\n",
    "    keys = list(job_desc.keys())\n",
    "    columns = ', '.join(keys)\n",
    "    index = keys.index('fold_id')\n",
    "    keys[index] = str(fold_id)\n",
    "    values_str = ', '.join(keys)\n",
    "    insert_job = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "    print(\"Inserting job with new fold: {}\".format(insert_job))\n",
    "    self.cursor_db.execute(insert_job)    \n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "print(\"Job {} with fold id {} updated/inserted\".format(fold_id, job_id))\n",
    "start = datetime.now()\n",
    "update_job = \"\"\"UPDATE {} set job_allocated_time = %s WHERE job_id = %s\"\"\".format(avail_jobs)\n",
    "self.cursor_db.execute(update_job, (start, job_id))\n",
    "select_job = \"\"\"SELECT * FROM {0} WHERE {0}.job_id = {1} AND {0}.interrupted = {2} FOR UPDATE\"\"\".format(\n",
    "    running_jobs, job_id, True)\n",
    "self.cursor_db.execute(select_job)\n",
    "count_ = len(self.cursor_db.fetchall())\n",
    "if count_ == 0:\n",
    "    insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    self.cursor_db.execute(insert_job)\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "else:\n",
    "    print(\"Job with job_id {} present in the updating and row locked\".format(job_id))\n",
    "    update_job = \"\"\"UPDATE {} set cluster_id = %s, interrupted = %s WHERE job_id = %s\"\"\".format(\n",
    "        running_jobs)\n",
    "    self.cursor_db.execute(update_job, (cluster_id, 'FALSE', job_id))\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"UNIQUE_MAX_OCCURRING\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
