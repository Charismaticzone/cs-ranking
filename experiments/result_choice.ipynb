{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from csrank.util import setup_logging\n",
    "from experiments.util import lp_metric_dict\n",
    "import numpy as np\n",
    "from experiments.dbconnection import DBConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1score, precision, recall, subset01loss, hammingloss, informedness, aucscore, averageprecisionscore\n"
     ]
    }
   ],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results.log')\n",
    "setup_logging(log_path=log_path)\n",
    "logger = logging.getLogger('ResultParsing')\n",
    "learning_problem = \"choice_function\"\n",
    "schema = \"choice_functions\"\n",
    "datasets = ['synthetic_choice', 'mnist_choice']\n",
    "keys = list(lp_metric_dict[learning_problem].keys())\n",
    "keys[-1] = keys[-1].format(6)\n",
    "metrics = ', '.join([x.lower() for x in keys])\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "#update_result = \"UPDATE results.discrete_choice set cluster_id = %s, CategoricalAccuracy = %s, CategoricalTopK2 = %s, CategoricalTopK3 = %s, CategoricalTopK4 = %s, CategoricalTopK5 = %s, CategoricalTopK6 = %s  where job_id= %s\"\n",
    "values = ('22412', '0.0636', '0.1329', '0.2200', '0.3250', '0.4517', '0.5950', '1002')\n",
    "self.init_connection()\n",
    "self.cursor_db.execute(update_result, tuple(values))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>f1score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>subset01loss</th>\n",
       "      <th>hammingloss</th>\n",
       "      <th>informedness</th>\n",
       "      <th>aucscore</th>\n",
       "      <th>averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FATE_CHOICE</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.4397</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8668</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.5876</td>\n",
       "      <td>0.6060</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.5052</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.7367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.6487</td>\n",
       "      <td>0.9563</td>\n",
       "      <td>0.8652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.5880</td>\n",
       "      <td>0.5981</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>0.8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>0.7211</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.6046</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.5869</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.8657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>0.5728</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.6513</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.8611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>0.6191</td>\n",
       "      <td>0.7214</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.8648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.6058</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.6398</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.8656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FETA_CHOICE_ZERO</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.9402</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FETA_CHOICE_ZERO</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FETA_CHOICE_ZERO</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FETA_CHOICE_ZERO</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.9956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FATE_CHOICE</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.5197</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FATE_CHOICE</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.5182</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>0.9821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FATE_CHOICE</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.9228</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FATE_CHOICE</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.9863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8668</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset           learner  f1score  precision  recall  subset01loss  \\\n",
       "0   PARETO       FATE_CHOICE   0.9250     0.9438  0.9241        0.4397   \n",
       "21  PARETO     RANDOM_CHOICE   0.2315     0.1332  1.0000        1.0000   \n",
       "20  PARETO        GLM_CHOICE   0.5876     0.6060  0.7402        0.9544   \n",
       "19  PARETO     RANDOM_CHOICE   0.2318     0.1334  1.0000        1.0000   \n",
       "18  PARETO        GLM_CHOICE   0.4924     0.5052  0.6432        0.9830   \n",
       "17  PARETO     RANDOM_CHOICE   0.2311     0.1329  1.0000        1.0000   \n",
       "16  PARETO    RANKSVM_CHOICE   0.5900     0.5957  0.7587        0.9572   \n",
       "15  PARETO    RANKSVM_CHOICE   0.5880     0.5981  0.7525        0.9559   \n",
       "14  PARETO        GLM_CHOICE   0.5719     0.5919  0.7211        0.9601   \n",
       "13  PARETO    RANKSVM_CHOICE   0.5885     0.6046  0.7436        0.9529   \n",
       "12  PARETO    RANKSVM_CHOICE   0.5869     0.5765  0.7806        0.9606   \n",
       "11  PARETO        GLM_CHOICE   0.5835     0.5728  0.7771        0.9615   \n",
       "10  PARETO        GLM_CHOICE   0.5881     0.6191  0.7214        0.9513   \n",
       "9   PARETO    RANKSVM_CHOICE   0.5888     0.6058  0.7427        0.9548   \n",
       "8   PARETO  FETA_CHOICE_ZERO   0.9350     0.9451  0.9491        0.3375   \n",
       "7   PARETO  FETA_CHOICE_ZERO   0.9448     0.9385  0.9699        0.3152   \n",
       "6   PARETO  FETA_CHOICE_ZERO   0.9439     0.9430  0.9651        0.3023   \n",
       "5   PARETO  FETA_CHOICE_ZERO   0.9334     0.9266  0.9644        0.3568   \n",
       "4   PARETO       FATE_CHOICE   0.9076     0.9078  0.9285        0.5197   \n",
       "3   PARETO       FATE_CHOICE   0.9057     0.9129  0.9208        0.5182   \n",
       "2   PARETO       FATE_CHOICE   0.9053     0.9087  0.9228        0.5214   \n",
       "1   PARETO       FATE_CHOICE   0.9191     0.9233  0.9334        0.4707   \n",
       "22  PARETO     RANDOM_CHOICE   0.2318     0.1334  1.0000        1.0000   \n",
       "23  PARETO     RANDOM_CHOICE   0.2315     0.1332  1.0000        1.0000   \n",
       "\n",
       "    hammingloss  informedness  aucscore  averageprecisionscore  \n",
       "0        0.0212        0.9135    0.9972                 0.9884  \n",
       "21       0.8668        0.0000    0.5000                 0.1332  \n",
       "20       0.1302        0.6377    0.9560                 0.8649  \n",
       "19       0.8666        0.0000    0.5000                 0.1334  \n",
       "18       0.1696        0.5095    0.8673                 0.7367  \n",
       "17       0.8671        0.0000    0.5000                 0.1329  \n",
       "16       0.1337        0.6487    0.9563                 0.8652  \n",
       "15       0.1339        0.6436    0.9561                 0.8649  \n",
       "14       0.1358        0.6150    0.9406                 0.8429  \n",
       "13       0.1303        0.6405    0.9562                 0.8655  \n",
       "12       0.1431        0.6562    0.9562                 0.8657  \n",
       "11       0.1447        0.6513    0.9529                 0.8611  \n",
       "10       0.1234        0.6297    0.9560                 0.8648  \n",
       "9        0.1301        0.6398    0.9565                 0.8656  \n",
       "8        0.0163        0.9402    0.9993                 0.9960  \n",
       "7        0.0139        0.9597    0.9992                 0.9958  \n",
       "6        0.0140        0.9558    0.9994                 0.9965  \n",
       "5        0.0169        0.9520    0.9992                 0.9956  \n",
       "4        0.0263        0.9111    0.9958                 0.9825  \n",
       "3        0.0267        0.9042    0.9957                 0.9821  \n",
       "2        0.0269        0.9058    0.9953                 0.9805  \n",
       "1        0.0229        0.9190    0.9967                 0.9863  \n",
       "22       0.8666        0.0000    0.5000                 0.1334  \n",
       "23       0.8668        0.0000    0.5000                 0.1332  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results_for_dataset(DATASET, del_jid = True):\n",
    "    config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "    results_table = 'results.{}'.format(learning_problem)\n",
    "    schema = 'choice_functions'\n",
    "    start = 3\n",
    "    select_jobs = \"SELECT learner_params, dataset_params, hp_ranges, {0}.job_id, dataset, learner, {3} from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset=\\'{2}\\'\"\n",
    "    self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "    self.init_connection()\n",
    "    avail_jobs = \"{}.avail_jobs\".format(schema)\n",
    "    select_st = select_jobs.format(results_table, avail_jobs, DATASET, metrics)\n",
    "    #print(select_st)\n",
    "    self.cursor_db.execute(select_st)\n",
    "    data = []\n",
    "    for job in self.cursor_db.fetchall():\n",
    "        job = dict(job)\n",
    "        if job['learner'] in job['hp_ranges'].keys():\n",
    "            n_hidden = job['hp_ranges'][job['learner']].get(\"n_hidden\", [])\n",
    "            if job['hp_ranges'][job['learner']].get(\"n_hidden_set_layers\", None)==[1,8]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "            elif n_hidden==[1,4] or n_hidden==[1,5]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "\n",
    "        if job['learner_params'].get(\"add_zeroth_order_model\", False):\n",
    "            job['learner'] = job['learner']+'_zero'\n",
    "        if \"letor\" in job['dataset']:\n",
    "            job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "        elif \"sushi\" in job['dataset']:\n",
    "            job['dataset'] =  job['dataset']\n",
    "        else:\n",
    "            job['dataset'] = job['dataset_params']['dataset_type']\n",
    "        job['learner'] = job['learner'].upper()\n",
    "        job['dataset'] = job['dataset'].upper()\n",
    "        values = list(job.values())\n",
    "        keys = list(job.keys())\n",
    "        columns = keys[start:]\n",
    "        vals = values[start:]\n",
    "        \n",
    "        data.append(vals)\n",
    "    df_full = pd.DataFrame(data, columns=columns)\n",
    "    df_full = df_full.sort_values('dataset')\n",
    "    if del_jid:\n",
    "        del df_full['job_id']\n",
    "    columns = list(df_full.columns)\n",
    "    return df_full, columns\n",
    "df, cols = get_results_for_dataset(datasets[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dfs(DATASET, latex_row=False):\n",
    "    df_full, columns = get_results_for_dataset(DATASET)\n",
    "    data = []\n",
    "    dataf = []\n",
    "    for dataset, dgroup in df_full.groupby(['dataset']):\n",
    "        max_feta = -100\n",
    "        max_fate = -100\n",
    "        max_ranknet = -100\n",
    "        feta_r = []\n",
    "        fate_r = []\n",
    "        ranknet_r = []\n",
    "        for learner, group in dgroup.groupby(['learner']):\n",
    "            one_row = [get_name(dataset), learner]\n",
    "            std = np.around(group.std(axis=0).values,3)\n",
    "            mean = np.around(group.mean(axis=0).values,3)\n",
    "            if np.all(np.isnan(std)):\n",
    "                one_row.extend([\"{:.4f}\".format(m) for m in mean])\n",
    "                #latex_row.extend([\"${:.3f}$\".format(m) for m in mean]) \n",
    "            else:\n",
    "                std_err = [s for s in std]\n",
    "                #std_err = [s/np.sqrt(len(group)) for s in std]\n",
    "                #one_row.extend([m for m in mean])\n",
    "                #one_row.extend([se for se in std_err])\n",
    "                #one_row.extend(mean)\n",
    "                if latex_row:\n",
    "                    one_row.extend([\"{:.3f}({:.0f})\".format(m, s*1e3) for m, s in zip(mean, std)])\n",
    "                else:\n",
    "                    one_row.extend([\"{:.3f}±{:.3f}\".format(m, s) for m, s in zip(mean, std)])\n",
    "            if \"FETA\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_feta = mean[0] - std[0]\n",
    "                    feta_r = one_row\n",
    "                    feta_r[1] = models_dict[\"FETA_CHOICE\"]\n",
    "            elif \"FATE\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_fate = mean[0] - std[0]\n",
    "                    fate_r = one_row\n",
    "                    fate_r[1] = models_dict[\"FATE_CHOICE\"]\n",
    "            elif \"RANKNET\" in str(learner):\n",
    "                if max_ranknet < mean[0] - std[0]:\n",
    "                    max_ranknet = mean[0] - std[0]\n",
    "                    ranknet_r = one_row\n",
    "                    ranknet_r[1] = models_dict[\"RANKNET_CHOICE\"]\n",
    "            else:\n",
    "                one_row[1] = models_dict[one_row[1]]\n",
    "                data.append(one_row)\n",
    "        data.append(feta_r)\n",
    "        data.append(ranknet_r)\n",
    "        data.append(fate_r)\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i].title()\n",
    "        if columns[i] == 'Learner':\n",
    "            columns[i] = \"ChoiceModel\"\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.sort_values(by='Dataset')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DCM</th>\n",
       "      <th>CategoricalAccuracy</th>\n",
       "      <th>Top-2</th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-4</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>GNL</td>\n",
       "      <td>0.218±0.062</td>\n",
       "      <td>0.366±0.071</td>\n",
       "      <td>0.502±0.018</td>\n",
       "      <td>0.608±0.023</td>\n",
       "      <td>0.685±0.022</td>\n",
       "      <td>0.754±0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>MLM</td>\n",
       "      <td>0.262±0.007</td>\n",
       "      <td>0.387±0.008</td>\n",
       "      <td>0.465±0.014</td>\n",
       "      <td>0.566±0.013</td>\n",
       "      <td>0.624±0.010</td>\n",
       "      <td>0.724±0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>MNL</td>\n",
       "      <td>0.270±0.006</td>\n",
       "      <td>0.387±0.005</td>\n",
       "      <td>0.502±0.002</td>\n",
       "      <td>0.581±0.018</td>\n",
       "      <td>0.676±0.011</td>\n",
       "      <td>0.786±0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>NLM</td>\n",
       "      <td>0.263±0.012</td>\n",
       "      <td>0.375±0.005</td>\n",
       "      <td>0.492±0.014</td>\n",
       "      <td>0.601±0.011</td>\n",
       "      <td>0.671±0.013</td>\n",
       "      <td>0.736±0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>PCL</td>\n",
       "      <td>0.269±0.006</td>\n",
       "      <td>0.387±0.006</td>\n",
       "      <td>0.500±0.012</td>\n",
       "      <td>0.595±0.018</td>\n",
       "      <td>0.676±0.010</td>\n",
       "      <td>0.785±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.258±0.004</td>\n",
       "      <td>0.372±0.007</td>\n",
       "      <td>0.480±0.022</td>\n",
       "      <td>0.594±0.017</td>\n",
       "      <td>0.679±0.013</td>\n",
       "      <td>0.779±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>FETA-Net-DC</td>\n",
       "      <td>0.292±0.007</td>\n",
       "      <td>0.401±0.023</td>\n",
       "      <td>0.507±0.026</td>\n",
       "      <td>0.602±0.040</td>\n",
       "      <td>0.687±0.032</td>\n",
       "      <td>0.769±0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>RankNetDC</td>\n",
       "      <td>0.269±0.013</td>\n",
       "      <td>0.436±0.020</td>\n",
       "      <td>0.555±0.025</td>\n",
       "      <td>0.661±0.014</td>\n",
       "      <td>0.758±0.021</td>\n",
       "      <td>0.831±0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUSHI</td>\n",
       "      <td>FATE-Net-DC</td>\n",
       "      <td>0.299±0.015</td>\n",
       "      <td>0.412±0.016</td>\n",
       "      <td>0.528±0.016</td>\n",
       "      <td>0.639±0.037</td>\n",
       "      <td>0.726±0.030</td>\n",
       "      <td>0.805±0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset          DCM CategoricalAccuracy        Top-2        Top-3  \\\n",
       "0   SUSHI          GNL         0.218±0.062  0.366±0.071  0.502±0.018   \n",
       "1   SUSHI          MLM         0.262±0.007  0.387±0.008  0.465±0.014   \n",
       "2   SUSHI          MNL         0.270±0.006  0.387±0.005  0.502±0.002   \n",
       "3   SUSHI          NLM         0.263±0.012  0.375±0.005  0.492±0.014   \n",
       "4   SUSHI          PCL         0.269±0.006  0.387±0.006  0.500±0.012   \n",
       "5   SUSHI  PairwiseSVM         0.258±0.004  0.372±0.007  0.480±0.022   \n",
       "6   SUSHI  FETA-Net-DC         0.292±0.007  0.401±0.023  0.507±0.026   \n",
       "7   SUSHI    RankNetDC         0.269±0.013  0.436±0.020  0.555±0.025   \n",
       "8   SUSHI  FATE-Net-DC         0.299±0.015  0.412±0.016  0.528±0.016   \n",
       "\n",
       "         Top-4        Top-5        Top-6  \n",
       "0  0.608±0.023  0.685±0.022  0.754±0.034  \n",
       "1  0.566±0.013  0.624±0.010  0.724±0.014  \n",
       "2  0.581±0.018  0.676±0.011  0.786±0.007  \n",
       "3  0.601±0.011  0.671±0.013  0.736±0.024  \n",
       "4  0.595±0.018  0.676±0.010  0.785±0.006  \n",
       "5  0.594±0.017  0.679±0.013  0.779±0.006  \n",
       "6  0.602±0.040  0.687±0.032  0.769±0.035  \n",
       "7  0.661±0.014  0.758±0.021  0.831±0.020  \n",
       "8  0.639±0.037  0.726±0.030  0.805±0.008  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    df = create_combined_dfs(dataset)\n",
    "    df_path = os.path.join(DIR_PATH, 'detailedresults' , dataset.split('_choice')[0].title()+'.csv')\n",
    "    df.to_csv(df_path, index=False, encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>categoricalaccuracy</th>\n",
       "      <th>categoricaltopk2</th>\n",
       "      <th>categoricaltopk3</th>\n",
       "      <th>categoricaltopk4</th>\n",
       "      <th>categoricaltopk5</th>\n",
       "      <th>categoricaltopk6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>GENERALIZED_EXTREME_VALUE</td>\n",
       "      <td>0.293(18)</td>\n",
       "      <td>0.369(20)</td>\n",
       "      <td>0.472(21)</td>\n",
       "      <td>0.567(18)</td>\n",
       "      <td>0.663(14)</td>\n",
       "      <td>0.756(9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>MIXED_LOGIT_MODEL</td>\n",
       "      <td>0.189(14)</td>\n",
       "      <td>0.338(17)</td>\n",
       "      <td>0.451(19)</td>\n",
       "      <td>0.542(20)</td>\n",
       "      <td>0.621(14)</td>\n",
       "      <td>0.692(10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>MULTINOMIAL_LOGIT_MODEL</td>\n",
       "      <td>0.201(8)</td>\n",
       "      <td>0.267(10)</td>\n",
       "      <td>0.360(10)</td>\n",
       "      <td>0.456(8)</td>\n",
       "      <td>0.559(4)</td>\n",
       "      <td>0.664(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>NESTED_LOGIT_MODEL</td>\n",
       "      <td>0.291(3)</td>\n",
       "      <td>0.416(5)</td>\n",
       "      <td>0.511(7)</td>\n",
       "      <td>0.582(6)</td>\n",
       "      <td>0.651(6)</td>\n",
       "      <td>0.722(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>PAIRED_COMBINATORIAL_LOGIT</td>\n",
       "      <td>0.185(1)</td>\n",
       "      <td>0.248(1)</td>\n",
       "      <td>0.340(2)</td>\n",
       "      <td>0.440(2)</td>\n",
       "      <td>0.550(2)</td>\n",
       "      <td>0.668(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.186(1)</td>\n",
       "      <td>0.248(1)</td>\n",
       "      <td>0.340(2)</td>\n",
       "      <td>0.439(2)</td>\n",
       "      <td>0.550(2)</td>\n",
       "      <td>0.667(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>FETA_DC</td>\n",
       "      <td>0.766(18)</td>\n",
       "      <td>0.874(15)</td>\n",
       "      <td>0.932(5)</td>\n",
       "      <td>0.960(2)</td>\n",
       "      <td>0.978(1)</td>\n",
       "      <td>0.990(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.203(4)</td>\n",
       "      <td>0.276(6)</td>\n",
       "      <td>0.369(6)</td>\n",
       "      <td>0.462(5)</td>\n",
       "      <td>0.562(4)</td>\n",
       "      <td>0.665(7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HYPERVOLUME</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.730(18)</td>\n",
       "      <td>0.855(19)</td>\n",
       "      <td>0.920(13)</td>\n",
       "      <td>0.949(9)</td>\n",
       "      <td>0.968(6)</td>\n",
       "      <td>0.980(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>GENERALIZED_EXTREME_VALUE</td>\n",
       "      <td>0.020(1)</td>\n",
       "      <td>0.085(2)</td>\n",
       "      <td>0.195(4)</td>\n",
       "      <td>0.338(3)</td>\n",
       "      <td>0.500(1)</td>\n",
       "      <td>0.661(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>MIXED_LOGIT_MODEL</td>\n",
       "      <td>0.003(1)</td>\n",
       "      <td>0.017(4)</td>\n",
       "      <td>0.055(12)</td>\n",
       "      <td>0.131(23)</td>\n",
       "      <td>0.249(32)</td>\n",
       "      <td>0.406(36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>MULTINOMIAL_LOGIT_MODEL</td>\n",
       "      <td>0.020(1)</td>\n",
       "      <td>0.082(3)</td>\n",
       "      <td>0.191(5)</td>\n",
       "      <td>0.336(4)</td>\n",
       "      <td>0.500(1)</td>\n",
       "      <td>0.663(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>NESTED_LOGIT_MODEL</td>\n",
       "      <td>0.049(14)</td>\n",
       "      <td>0.126(19)</td>\n",
       "      <td>0.216(6)</td>\n",
       "      <td>0.330(13)</td>\n",
       "      <td>0.462(27)</td>\n",
       "      <td>0.608(31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>PAIRED_COMBINATORIAL_LOGIT</td>\n",
       "      <td>0.088(12)</td>\n",
       "      <td>0.187(14)</td>\n",
       "      <td>0.291(17)</td>\n",
       "      <td>0.397(21)</td>\n",
       "      <td>0.501(22)</td>\n",
       "      <td>0.604(17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.021(1)</td>\n",
       "      <td>0.085(5)</td>\n",
       "      <td>0.194(9)</td>\n",
       "      <td>0.337(7)</td>\n",
       "      <td>0.501(2)</td>\n",
       "      <td>0.663(9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>FETA_DC</td>\n",
       "      <td>0.846(10)</td>\n",
       "      <td>0.971(4)</td>\n",
       "      <td>0.994(1)</td>\n",
       "      <td>0.999(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.531(9)</td>\n",
       "      <td>0.757(7)</td>\n",
       "      <td>0.873(6)</td>\n",
       "      <td>0.936(5)</td>\n",
       "      <td>0.970(3)</td>\n",
       "      <td>0.987(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MEDOID</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.881(7)</td>\n",
       "      <td>0.980(3)</td>\n",
       "      <td>0.996(1)</td>\n",
       "      <td>0.999(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "      <td>1.000(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>GENERALIZED_EXTREME_VALUE</td>\n",
       "      <td>0.078(2)</td>\n",
       "      <td>0.175(3)</td>\n",
       "      <td>0.280(4)</td>\n",
       "      <td>0.389(2)</td>\n",
       "      <td>0.499(1)</td>\n",
       "      <td>0.611(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>MIXED_LOGIT_MODEL</td>\n",
       "      <td>0.039(1)</td>\n",
       "      <td>0.103(3)</td>\n",
       "      <td>0.187(5)</td>\n",
       "      <td>0.284(6)</td>\n",
       "      <td>0.396(6)</td>\n",
       "      <td>0.518(7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>MULTINOMIAL_LOGIT_MODEL</td>\n",
       "      <td>0.078(0)</td>\n",
       "      <td>0.176(1)</td>\n",
       "      <td>0.281(1)</td>\n",
       "      <td>0.390(2)</td>\n",
       "      <td>0.500(2)</td>\n",
       "      <td>0.610(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>NESTED_LOGIT_MODEL</td>\n",
       "      <td>0.069(5)</td>\n",
       "      <td>0.151(12)</td>\n",
       "      <td>0.242(18)</td>\n",
       "      <td>0.339(23)</td>\n",
       "      <td>0.441(23)</td>\n",
       "      <td>0.550(22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>PAIRED_COMBINATORIAL_LOGIT</td>\n",
       "      <td>0.081(2)</td>\n",
       "      <td>0.179(4)</td>\n",
       "      <td>0.284(4)</td>\n",
       "      <td>0.392(3)</td>\n",
       "      <td>0.501(3)</td>\n",
       "      <td>0.610(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>RANKSVM_DC</td>\n",
       "      <td>0.079(1)</td>\n",
       "      <td>0.177(2)</td>\n",
       "      <td>0.282(2)</td>\n",
       "      <td>0.391(2)</td>\n",
       "      <td>0.500(1)</td>\n",
       "      <td>0.610(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>FETA_DC</td>\n",
       "      <td>0.124(7)</td>\n",
       "      <td>0.246(12)</td>\n",
       "      <td>0.363(15)</td>\n",
       "      <td>0.476(19)</td>\n",
       "      <td>0.582(19)</td>\n",
       "      <td>0.682(19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>RANKNET_DC</td>\n",
       "      <td>0.102(7)</td>\n",
       "      <td>0.209(10)</td>\n",
       "      <td>0.317(13)</td>\n",
       "      <td>0.426(14)</td>\n",
       "      <td>0.533(14)</td>\n",
       "      <td>0.637(14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NEAREST_NEIGHBOUR_MEDOID</td>\n",
       "      <td>FATE_DC</td>\n",
       "      <td>0.118(1)</td>\n",
       "      <td>0.235(2)</td>\n",
       "      <td>0.351(2)</td>\n",
       "      <td>0.465(2)</td>\n",
       "      <td>0.574(2)</td>\n",
       "      <td>0.679(3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dataset                     learner categoricalaccuracy  \\\n",
       "0                HYPERVOLUME   GENERALIZED_EXTREME_VALUE           0.293(18)   \n",
       "1                HYPERVOLUME           MIXED_LOGIT_MODEL           0.189(14)   \n",
       "2                HYPERVOLUME     MULTINOMIAL_LOGIT_MODEL            0.201(8)   \n",
       "3                HYPERVOLUME          NESTED_LOGIT_MODEL            0.291(3)   \n",
       "4                HYPERVOLUME  PAIRED_COMBINATORIAL_LOGIT            0.185(1)   \n",
       "5                HYPERVOLUME                  RANKSVM_DC            0.186(1)   \n",
       "6                HYPERVOLUME                     FETA_DC           0.766(18)   \n",
       "7                HYPERVOLUME                  RANKNET_DC            0.203(4)   \n",
       "8                HYPERVOLUME                     FATE_DC           0.730(18)   \n",
       "9                     MEDOID   GENERALIZED_EXTREME_VALUE            0.020(1)   \n",
       "10                    MEDOID           MIXED_LOGIT_MODEL            0.003(1)   \n",
       "11                    MEDOID     MULTINOMIAL_LOGIT_MODEL            0.020(1)   \n",
       "12                    MEDOID          NESTED_LOGIT_MODEL           0.049(14)   \n",
       "13                    MEDOID  PAIRED_COMBINATORIAL_LOGIT           0.088(12)   \n",
       "14                    MEDOID                  RANKSVM_DC            0.021(1)   \n",
       "15                    MEDOID                     FETA_DC           0.846(10)   \n",
       "16                    MEDOID                  RANKNET_DC            0.531(9)   \n",
       "17                    MEDOID                     FATE_DC            0.881(7)   \n",
       "18  NEAREST_NEIGHBOUR_MEDOID   GENERALIZED_EXTREME_VALUE            0.078(2)   \n",
       "19  NEAREST_NEIGHBOUR_MEDOID           MIXED_LOGIT_MODEL            0.039(1)   \n",
       "20  NEAREST_NEIGHBOUR_MEDOID     MULTINOMIAL_LOGIT_MODEL            0.078(0)   \n",
       "21  NEAREST_NEIGHBOUR_MEDOID          NESTED_LOGIT_MODEL            0.069(5)   \n",
       "22  NEAREST_NEIGHBOUR_MEDOID  PAIRED_COMBINATORIAL_LOGIT            0.081(2)   \n",
       "23  NEAREST_NEIGHBOUR_MEDOID                  RANKSVM_DC            0.079(1)   \n",
       "24  NEAREST_NEIGHBOUR_MEDOID                     FETA_DC            0.124(7)   \n",
       "25  NEAREST_NEIGHBOUR_MEDOID                  RANKNET_DC            0.102(7)   \n",
       "26  NEAREST_NEIGHBOUR_MEDOID                     FATE_DC            0.118(1)   \n",
       "\n",
       "   categoricaltopk2 categoricaltopk3 categoricaltopk4 categoricaltopk5  \\\n",
       "0         0.369(20)        0.472(21)        0.567(18)        0.663(14)   \n",
       "1         0.338(17)        0.451(19)        0.542(20)        0.621(14)   \n",
       "2         0.267(10)        0.360(10)         0.456(8)         0.559(4)   \n",
       "3          0.416(5)         0.511(7)         0.582(6)         0.651(6)   \n",
       "4          0.248(1)         0.340(2)         0.440(2)         0.550(2)   \n",
       "5          0.248(1)         0.340(2)         0.439(2)         0.550(2)   \n",
       "6         0.874(15)         0.932(5)         0.960(2)         0.978(1)   \n",
       "7          0.276(6)         0.369(6)         0.462(5)         0.562(4)   \n",
       "8         0.855(19)        0.920(13)         0.949(9)         0.968(6)   \n",
       "9          0.085(2)         0.195(4)         0.338(3)         0.500(1)   \n",
       "10         0.017(4)        0.055(12)        0.131(23)        0.249(32)   \n",
       "11         0.082(3)         0.191(5)         0.336(4)         0.500(1)   \n",
       "12        0.126(19)         0.216(6)        0.330(13)        0.462(27)   \n",
       "13        0.187(14)        0.291(17)        0.397(21)        0.501(22)   \n",
       "14         0.085(5)         0.194(9)         0.337(7)         0.501(2)   \n",
       "15         0.971(4)         0.994(1)         0.999(0)         1.000(0)   \n",
       "16         0.757(7)         0.873(6)         0.936(5)         0.970(3)   \n",
       "17         0.980(3)         0.996(1)         0.999(0)         1.000(0)   \n",
       "18         0.175(3)         0.280(4)         0.389(2)         0.499(1)   \n",
       "19         0.103(3)         0.187(5)         0.284(6)         0.396(6)   \n",
       "20         0.176(1)         0.281(1)         0.390(2)         0.500(2)   \n",
       "21        0.151(12)        0.242(18)        0.339(23)        0.441(23)   \n",
       "22         0.179(4)         0.284(4)         0.392(3)         0.501(3)   \n",
       "23         0.177(2)         0.282(2)         0.391(2)         0.500(1)   \n",
       "24        0.246(12)        0.363(15)        0.476(19)        0.582(19)   \n",
       "25        0.209(10)        0.317(13)        0.426(14)        0.533(14)   \n",
       "26         0.235(2)         0.351(2)         0.465(2)         0.574(2)   \n",
       "\n",
       "   categoricaltopk6  \n",
       "0          0.756(9)  \n",
       "1         0.692(10)  \n",
       "2          0.664(4)  \n",
       "3          0.722(4)  \n",
       "4          0.668(2)  \n",
       "5          0.667(2)  \n",
       "6          0.990(2)  \n",
       "7          0.665(7)  \n",
       "8          0.980(3)  \n",
       "9          0.661(5)  \n",
       "10        0.406(36)  \n",
       "11         0.663(4)  \n",
       "12        0.608(31)  \n",
       "13        0.604(17)  \n",
       "14         0.663(9)  \n",
       "15         1.000(0)  \n",
       "16         0.987(2)  \n",
       "17         1.000(0)  \n",
       "18         0.611(3)  \n",
       "19         0.518(7)  \n",
       "20         0.610(3)  \n",
       "21        0.550(22)  \n",
       "22         0.610(3)  \n",
       "23         0.610(2)  \n",
       "24        0.682(19)  \n",
       "25        0.637(14)  \n",
       "26         0.679(3)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_combined_dfs(DATASET, latex_row=True)\n",
    "df.sort_values(by='dataset')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_ranker(sub_df):\n",
    "    remove_ranker = None\n",
    "    if len(sub_df)==2:\n",
    "        sub_df = sub_df[:,1:3]\n",
    "        val1 = [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", sub_df[0][1])]\n",
    "        val2 = [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", sub_df[1][1])]\n",
    "        val1 = val1[0] if len(val1)==1 else val1[0] - val1[1]*1e-3\n",
    "        val2 = val2[0] if len(val2)==1 else val2[0] - val2[1]*1e-3\n",
    "        if val1 < val2 :\n",
    "            remove_ranker = sub_df[0][0]\n",
    "        else:\n",
    "            remove_ranker = sub_df[1][0]\n",
    "    \n",
    "    return remove_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    return [vals[0], vals[0] - vals[1]*1e-3]\n",
    "def mark_best(df):\n",
    "    for col in list(df.columns)[1:]:\n",
    "        values_str = df[['learner',col]].as_matrix()\n",
    "        values = np.array([get_val(val[1])for val in values_str])\n",
    "        maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0]\n",
    "        for ind in maxi:\n",
    "            values_str[ind] = [values_str[ind][0], \"bfseries {}\".format(values_str[ind][1])]\n",
    "        df['learner'] = values_str[:,0]\n",
    "        df[col] = values_str[:,1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name HYPERVOLUME\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "learner & categoricalaccuracy & categoricaltopk2 & categoricaltopk3 & categoricaltopk4 & categoricaltopk5\\\\\n",
      "\\midrule\n",
      "\\pairwisesvm & 0.186(1) & 0.248(1) & 0.340(2) & 0.439(2) & 0.550(2)\\\\\n",
      "\\ranknetdc & 0.203(4) & 0.276(6) & 0.369(6) & 0.462(5) & 0.562(4)\\\\\n",
      "\\mnl & 0.201(8) & 0.267(10) & 0.360(10) & 0.456(8) & 0.559(4)\\\\\n",
      "\\nlm & 0.291(3) & 0.416(5) & 0.511(7) & 0.582(6) & 0.651(6)\\\\\n",
      "\\gnl & 0.293(18) & 0.369(20) & 0.472(21) & 0.567(18) & 0.663(14)\\\\\n",
      "\\pcl & 0.185(1) & 0.248(1) & 0.340(2) & 0.440(2) & 0.550(2)\\\\\n",
      "\\mlm & 0.189(14) & 0.338(17) & 0.451(19) & 0.542(20) & 0.621(14)\\\\\n",
      "\\fatedc & 0.730(18) & 0.855(19) & 0.920(13) & 0.949(9) & 0.968(6)\\\\\n",
      "\\fetadc & \\bfseries 0.766(18) & \\bfseries 0.874(15) & \\bfseries 0.932(5) & \\bfseries 0.960(2) & \\bfseries 0.978(1)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "name MEDOID\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "learner & categoricalaccuracy & categoricaltopk2 & categoricaltopk3 & categoricaltopk4 & categoricaltopk5\\\\\n",
      "\\midrule\n",
      "\\pairwisesvm & 0.021(1) & 0.085(5) & 0.194(9) & 0.337(7) & 0.501(2)\\\\\n",
      "\\ranknetdc & 0.531(9) & 0.757(7) & 0.873(6) & 0.936(5) & 0.970(3)\\\\\n",
      "\\mnl & 0.020(1) & 0.082(3) & 0.191(5) & 0.336(4) & 0.500(1)\\\\\n",
      "\\nlm & 0.049(14) & 0.126(19) & 0.216(6) & 0.330(13) & 0.462(27)\\\\\n",
      "\\gnl & 0.020(1) & 0.085(2) & 0.195(4) & 0.338(3) & 0.500(1)\\\\\n",
      "\\pcl & 0.088(12) & 0.187(14) & 0.291(17) & 0.397(21) & 0.501(22)\\\\\n",
      "\\mlm & 0.003(1) & 0.017(4) & 0.055(12) & 0.131(23) & 0.249(32)\\\\\n",
      "\\fatedc & \\bfseries 0.881(7) & \\bfseries 0.980(3) & \\bfseries 0.996(1) & \\bfseries 0.999(0) & \\bfseries 1.000(0)\\\\\n",
      "\\fetadc & 0.846(10) & 0.971(4) & 0.994(1) & \\bfseries 0.999(0) & \\bfseries 1.000(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "name NEAREST_NEIGHBOUR_MEDOID\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "learner & categoricalaccuracy & categoricaltopk2 & categoricaltopk3 & categoricaltopk4 & categoricaltopk5\\\\\n",
      "\\midrule\n",
      "\\pairwisesvm & 0.079(1) & 0.177(2) & 0.282(2) & 0.391(2) & 0.500(1)\\\\\n",
      "\\ranknetdc & 0.102(7) & 0.209(10) & 0.317(13) & 0.426(14) & 0.533(14)\\\\\n",
      "\\mnl & 0.078(0) & 0.176(1) & 0.281(1) & 0.390(2) & 0.500(2)\\\\\n",
      "\\nlm & 0.069(5) & 0.151(12) & 0.242(18) & 0.339(23) & 0.441(23)\\\\\n",
      "\\gnl & 0.078(2) & 0.175(3) & 0.280(4) & 0.389(2) & 0.499(1)\\\\\n",
      "\\pcl & 0.081(2) & 0.179(4) & 0.284(4) & 0.392(3) & 0.501(3)\\\\\n",
      "\\mlm & 0.039(1) & 0.103(3) & 0.187(5) & 0.284(6) & 0.396(6)\\\\\n",
      "\\fatedc & 0.118(1) & 0.235(2) & 0.351(2) & 0.465(2) & 0.574(2)\\\\\n",
      "\\fetadc & \\bfseries 0.124(7) & \\bfseries 0.246(12) & \\bfseries 0.363(15) & \\bfseries 0.476(19) & \\bfseries 0.582(19)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from tabulate import tabulate\n",
    "import string\n",
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    \n",
    "    remove_rankers = []\n",
    "    sub_df = group[group['learner'].str.contains(\"FETA\")].as_matrix()\n",
    "    r1 = remove_ranker(sub_df)\n",
    "    sub_df = group[group['learner'].str.contains(\"FATE\")].as_matrix()\n",
    "    r2 = remove_ranker(sub_df)\n",
    "    sub_df = group[group['learner'].str.contains(\"RANKNET\")].as_matrix()\n",
    "    r3 = remove_ranker(sub_df)\n",
    "    remove_rankers.append(r1)\n",
    "    remove_rankers.append(r2)\n",
    "    remove_rankers.append(r3)\n",
    "    group = group[~group['learner'].isin(remove_rankers)]\n",
    "    group = group.replace({'FETA_DC_SHALLOW_ZERO': \"FETA_DC\"})\n",
    "    group = group.replace({'FATE_DC_SHALLOW': \"FATE_DC\"})\n",
    "    group = group.replace({'RANKNET_DC_SHALLOW': \"RANKNET_DC\"})\n",
    "    custom_dict = {\"RANKSVM_DC\":0, \"RANKNET_DC\":1, 'MULTINOMIAL_LOGIT_MODEL':2, 'NESTED_LOGIT_MODEL':3, 'GENERALIZED_EXTREME_VALUE':4, \n",
    "                   'PAIRED_COMBINATORIAL_LOGIT':5, \"MIXED_LOGIT_MODEL\":6, \"FATE_DC\":7, \"FETA_DC\":8, \"FETA_DC_ZERO\":9}\n",
    "    group['rank'] = group['learner'].map(custom_dict)\n",
    "    group.sort_values(by='rank', inplace=True)\n",
    "    del group[\"dataset\"]\n",
    "    del group['rank']\n",
    "    group = mark_best(group)\n",
    "    if len(group)==9:\n",
    "        group['learner'] = [\"pairwisesvm\", \"ranknetdc\", \"mnl\", \"nlm\", \"gnl\", \"pcl\", \"mlm\", \"fatedc\", \"fetadc\"]\n",
    "    print(\"name {}\".format(name))\n",
    "    group = group.drop(columns='categoricaltopk6')\n",
    "    if \"N_5\" in name:\n",
    "        group = group.drop(columns='categoricaltopk5')\n",
    "    latex_code = group.to_latex(index = False)\n",
    "    latex_code = latex_code.replace(' ',\"\")\n",
    "    latex_code = latex_code.replace('&',\" & \")\n",
    "    latex_code = str(latex_code)\n",
    "    for learner in group['learner']:\n",
    "        latex_code = latex_code.replace(learner, \"\\\\{}\".format(learner))\n",
    "    latex_code = latex_code.replace(\"bfseries\", \"\\\\{} \".format(\"bfseries\"))\n",
    "    #latex_code = latex_code.replace(\"0.\", \".\")\n",
    "\n",
    "    print(latex_code)\n",
    "#df.T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = os.path.join(DIR_PATH, 'results' , \"discrete_choice.csv\")\n",
    "\n",
    "if not os.path.isfile(df_path):\n",
    "    dataFrame = df\n",
    "else:\n",
    "    dataFrame = pd.read_csv(df_path, index_col=0)\n",
    "    dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "dataFrame\n",
    "dataFrame.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)\n",
    "\n",
    "X_train = np.arange(40).reshape(4,5,2)\n",
    "\n",
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "self.schema = 'pymc3'\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "fold_id = 1\n",
    "cluster_id=1234\n",
    "self.fetch_job_arguments(cluster_id=cluster_id)\n",
    "self.init_connection(cursor_factory=None)\n",
    "job_desc = dict(self.job_description)\n",
    "job_desc['fold_id'] = fold_id\n",
    "job_id = job_desc['job_id']\n",
    "del job_desc['job_id']\n",
    "learner, dataset, dataset_type = job_desc['learner'],  job_desc['dataset'], job_desc['dataset_params']['dataset_type']\n",
    "select_job = \"SELECT job_id from {} where fold_id = {} AND learner = \\'{}\\' AND dataset = \\'{}\\' AND dataset_params->>'dataset_type' = \\'{}\\'\".format(\n",
    "    avail_jobs, fold_id, learner, dataset, dataset_type)\n",
    "self.cursor_db.execute(select_job)\n",
    "\n",
    "if self.cursor_db.rowcount == 0:\n",
    "    keys = list(job_desc.keys())\n",
    "    columns = ', '.join(keys)\n",
    "    index = keys.index('fold_id')\n",
    "    keys[index] = str(fold_id)\n",
    "    values_str = ', '.join(keys)\n",
    "    insert_job = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "    print(\"Inserting job with new fold: {}\".format(insert_job))\n",
    "    self.cursor_db.execute(insert_job)    \n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "print(\"Job {} with fold id {} updated/inserted\".format(fold_id, job_id))\n",
    "start = datetime.now()\n",
    "update_job = \"\"\"UPDATE {} set job_allocated_time = %s WHERE job_id = %s\"\"\".format(avail_jobs)\n",
    "self.cursor_db.execute(update_job, (start, job_id))\n",
    "select_job = \"\"\"SELECT * FROM {0} WHERE {0}.job_id = {1} AND {0}.interrupted = {2} FOR UPDATE\"\"\".format(\n",
    "    running_jobs, job_id, True)\n",
    "self.cursor_db.execute(select_job)\n",
    "count_ = len(self.cursor_db.fetchall())\n",
    "if count_ == 0:\n",
    "    insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    self.cursor_db.execute(insert_job)\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "else:\n",
    "    print(\"Job with job_id {} present in the updating and row locked\".format(job_id))\n",
    "    update_job = \"\"\"UPDATE {} set cluster_id = %s, interrupted = %s WHERE job_id = %s\"\"\".format(\n",
    "        running_jobs)\n",
    "    self.cursor_db.execute(update_job, (cluster_id, 'FALSE', job_id))\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"UNIQUE_MAX_OCCURRING\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
